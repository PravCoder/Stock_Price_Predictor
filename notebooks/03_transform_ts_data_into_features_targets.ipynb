{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pravachanpatra/Documents/PYTHON/AI_ML_DL/Stock_Price_Predictor/venv/bin/python\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>vw_avr_price</th>\n",
       "      <th>open_price</th>\n",
       "      <th>close_price</th>\n",
       "      <th>high_price</th>\n",
       "      <th>low_price</th>\n",
       "      <th>num_transactions</th>\n",
       "      <th>datetime</th>\n",
       "      <th>price_diff</th>\n",
       "      <th>volume_sma_5</th>\n",
       "      <th>volume_change</th>\n",
       "      <th>SMA_5</th>\n",
       "      <th>SMA_20</th>\n",
       "      <th>EMA_5</th>\n",
       "      <th>EMA_20</th>\n",
       "      <th>vol_5</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.669698e+07</td>\n",
       "      <td>164.743200</td>\n",
       "      <td>163.210000</td>\n",
       "      <td>165.35</td>\n",
       "      <td>165.850000</td>\n",
       "      <td>163.00</td>\n",
       "      <td>491310.000000</td>\n",
       "      <td>2022-08-02 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.694134e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>165.318000</td>\n",
       "      <td>169.103000</td>\n",
       "      <td>165.350000</td>\n",
       "      <td>165.350000</td>\n",
       "      <td>0.071554</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.669698e+07</td>\n",
       "      <td>164.743200</td>\n",
       "      <td>163.210000</td>\n",
       "      <td>165.35</td>\n",
       "      <td>165.850000</td>\n",
       "      <td>163.00</td>\n",
       "      <td>491310.000000</td>\n",
       "      <td>2022-08-03 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.694134e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>165.318000</td>\n",
       "      <td>169.103000</td>\n",
       "      <td>165.350000</td>\n",
       "      <td>165.350000</td>\n",
       "      <td>0.071554</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.669698e+07</td>\n",
       "      <td>164.743200</td>\n",
       "      <td>163.210000</td>\n",
       "      <td>165.35</td>\n",
       "      <td>165.850000</td>\n",
       "      <td>163.00</td>\n",
       "      <td>491310.000000</td>\n",
       "      <td>2022-08-04 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.694134e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>165.318000</td>\n",
       "      <td>169.103000</td>\n",
       "      <td>165.350000</td>\n",
       "      <td>165.350000</td>\n",
       "      <td>0.071554</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.669698e+07</td>\n",
       "      <td>164.743200</td>\n",
       "      <td>163.210000</td>\n",
       "      <td>165.35</td>\n",
       "      <td>165.850000</td>\n",
       "      <td>163.00</td>\n",
       "      <td>491310.000000</td>\n",
       "      <td>2022-08-05 04:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.694134e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>165.318000</td>\n",
       "      <td>169.103000</td>\n",
       "      <td>165.350000</td>\n",
       "      <td>165.350000</td>\n",
       "      <td>0.071554</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.791877e+07</td>\n",
       "      <td>165.126767</td>\n",
       "      <td>164.263333</td>\n",
       "      <td>165.19</td>\n",
       "      <td>166.503333</td>\n",
       "      <td>163.40</td>\n",
       "      <td>507545.666667</td>\n",
       "      <td>2022-08-06 00:00:00</td>\n",
       "      <td>-0.160000</td>\n",
       "      <td>5.694134e+07</td>\n",
       "      <td>0.021549</td>\n",
       "      <td>165.318000</td>\n",
       "      <td>169.103000</td>\n",
       "      <td>165.296667</td>\n",
       "      <td>165.334762</td>\n",
       "      <td>0.071554</td>\n",
       "      <td>-0.000968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>3.515373e+07</td>\n",
       "      <td>218.131900</td>\n",
       "      <td>216.960000</td>\n",
       "      <td>218.24</td>\n",
       "      <td>219.300000</td>\n",
       "      <td>215.75</td>\n",
       "      <td>604680.000000</td>\n",
       "      <td>2024-07-29 04:00:00</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>4.008290e+07</td>\n",
       "      <td>-0.042438</td>\n",
       "      <td>217.978000</td>\n",
       "      <td>225.414500</td>\n",
       "      <td>218.726415</td>\n",
       "      <td>221.994869</td>\n",
       "      <td>0.292077</td>\n",
       "      <td>0.000428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>4.068162e+07</td>\n",
       "      <td>218.405900</td>\n",
       "      <td>219.190000</td>\n",
       "      <td>218.80</td>\n",
       "      <td>220.325000</td>\n",
       "      <td>216.12</td>\n",
       "      <td>584305.000000</td>\n",
       "      <td>2024-07-30 04:00:00</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>3.812887e+07</td>\n",
       "      <td>0.157249</td>\n",
       "      <td>218.240000</td>\n",
       "      <td>224.705500</td>\n",
       "      <td>218.750943</td>\n",
       "      <td>221.690596</td>\n",
       "      <td>0.329983</td>\n",
       "      <td>0.002566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>4.842297e+07</td>\n",
       "      <td>222.344100</td>\n",
       "      <td>221.440000</td>\n",
       "      <td>222.08</td>\n",
       "      <td>223.820000</td>\n",
       "      <td>220.63</td>\n",
       "      <td>668833.000000</td>\n",
       "      <td>2024-07-31 04:00:00</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>3.984794e+07</td>\n",
       "      <td>0.190291</td>\n",
       "      <td>219.064000</td>\n",
       "      <td>224.431000</td>\n",
       "      <td>219.860629</td>\n",
       "      <td>221.727682</td>\n",
       "      <td>1.710839</td>\n",
       "      <td>0.014991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>6.112524e+07</td>\n",
       "      <td>219.477300</td>\n",
       "      <td>224.370000</td>\n",
       "      <td>218.36</td>\n",
       "      <td>224.480000</td>\n",
       "      <td>217.02</td>\n",
       "      <td>876046.000000</td>\n",
       "      <td>2024-08-01 04:00:00</td>\n",
       "      <td>-3.720000</td>\n",
       "      <td>4.441905e+07</td>\n",
       "      <td>0.262319</td>\n",
       "      <td>219.125333</td>\n",
       "      <td>223.822000</td>\n",
       "      <td>219.360419</td>\n",
       "      <td>221.406950</td>\n",
       "      <td>1.670571</td>\n",
       "      <td>-0.016751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>6.112524e+07</td>\n",
       "      <td>219.477300</td>\n",
       "      <td>224.370000</td>\n",
       "      <td>218.36</td>\n",
       "      <td>224.480000</td>\n",
       "      <td>217.02</td>\n",
       "      <td>876046.000000</td>\n",
       "      <td>2024-08-02 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.930176e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>219.168000</td>\n",
       "      <td>223.148667</td>\n",
       "      <td>219.026946</td>\n",
       "      <td>221.116765</td>\n",
       "      <td>1.641804</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>732 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           volume  vw_avr_price  open_price  close_price  high_price  \\\n",
       "0    5.669698e+07    164.743200  163.210000       165.35  165.850000   \n",
       "1    5.669698e+07    164.743200  163.210000       165.35  165.850000   \n",
       "2    5.669698e+07    164.743200  163.210000       165.35  165.850000   \n",
       "3    5.669698e+07    164.743200  163.210000       165.35  165.850000   \n",
       "4    5.791877e+07    165.126767  164.263333       165.19  166.503333   \n",
       "..            ...           ...         ...          ...         ...   \n",
       "727  3.515373e+07    218.131900  216.960000       218.24  219.300000   \n",
       "728  4.068162e+07    218.405900  219.190000       218.80  220.325000   \n",
       "729  4.842297e+07    222.344100  221.440000       222.08  223.820000   \n",
       "730  6.112524e+07    219.477300  224.370000       218.36  224.480000   \n",
       "731  6.112524e+07    219.477300  224.370000       218.36  224.480000   \n",
       "\n",
       "     low_price  num_transactions            datetime  price_diff  \\\n",
       "0       163.00     491310.000000 2022-08-02 00:00:00    0.000000   \n",
       "1       163.00     491310.000000 2022-08-03 00:00:00    0.000000   \n",
       "2       163.00     491310.000000 2022-08-04 00:00:00    0.000000   \n",
       "3       163.00     491310.000000 2022-08-05 04:00:00    0.000000   \n",
       "4       163.40     507545.666667 2022-08-06 00:00:00   -0.160000   \n",
       "..         ...               ...                 ...         ...   \n",
       "727     215.75     604680.000000 2024-07-29 04:00:00    0.093333   \n",
       "728     216.12     584305.000000 2024-07-30 04:00:00    0.560000   \n",
       "729     220.63     668833.000000 2024-07-31 04:00:00    3.280000   \n",
       "730     217.02     876046.000000 2024-08-01 04:00:00   -3.720000   \n",
       "731     217.02     876046.000000 2024-08-02 00:00:00    0.000000   \n",
       "\n",
       "     volume_sma_5  volume_change       SMA_5      SMA_20       EMA_5  \\\n",
       "0    5.694134e+07       0.000000  165.318000  169.103000  165.350000   \n",
       "1    5.694134e+07       0.000000  165.318000  169.103000  165.350000   \n",
       "2    5.694134e+07       0.000000  165.318000  169.103000  165.350000   \n",
       "3    5.694134e+07       0.000000  165.318000  169.103000  165.350000   \n",
       "4    5.694134e+07       0.021549  165.318000  169.103000  165.296667   \n",
       "..            ...            ...         ...         ...         ...   \n",
       "727  4.008290e+07      -0.042438  217.978000  225.414500  218.726415   \n",
       "728  3.812887e+07       0.157249  218.240000  224.705500  218.750943   \n",
       "729  3.984794e+07       0.190291  219.064000  224.431000  219.860629   \n",
       "730  4.441905e+07       0.262319  219.125333  223.822000  219.360419   \n",
       "731  4.930176e+07       0.000000  219.168000  223.148667  219.026946   \n",
       "\n",
       "         EMA_20     vol_5  daily_return  \n",
       "0    165.350000  0.071554      0.000000  \n",
       "1    165.350000  0.071554      0.000000  \n",
       "2    165.350000  0.071554      0.000000  \n",
       "3    165.350000  0.071554      0.000000  \n",
       "4    165.334762  0.071554     -0.000968  \n",
       "..          ...       ...           ...  \n",
       "727  221.994869  0.292077      0.000428  \n",
       "728  221.690596  0.329983      0.002566  \n",
       "729  221.727682  1.710839      0.014991  \n",
       "730  221.406950  1.670571     -0.016751  \n",
       "731  221.116765  1.641804      0.000000  \n",
       "\n",
       "[732 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "# Verify kernal path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# time series dataframe\n",
    "ts_prices = pd.read_parquet(\"../data/transformed/validated_prices_2022-08-02-2024-08-02.parquet\") # reads in parquet-file in specified path and returns its data in a dataframe\n",
    "ts_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 13),\n",
       " (1, 14),\n",
       " (2, 15),\n",
       " (3, 16),\n",
       " (4, 17),\n",
       " (5, 18),\n",
       " (6, 19),\n",
       " (7, 20),\n",
       " (8, 21),\n",
       " (9, 22)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_cutoff_indicies(data, n_previous_days, step_size):\n",
    "    stop_position = len(data)-1\n",
    "\n",
    "    first_indx = 0\n",
    "    last_indx = n_previous_days+1  # target index\n",
    "    indicies = []\n",
    "\n",
    "    while last_indx <= stop_position:\n",
    "        indicies.append((first_indx, last_indx))\n",
    "\n",
    "        first_indx += step_size\n",
    "        last_indx += step_size\n",
    "    \n",
    "    return indicies\n",
    "\n",
    "n_previous_days = 12  # make sure this constant across all uses\n",
    "step_size = 1\n",
    "indicies = get_cutoff_indicies(ts_prices, n_previous_days, step_size)\n",
    "indicies[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 13), (1, 14), (2, 15), (3, 16), (4, 17), (5, 18), (6, 19), (7, 20), (8, 21), (9, 22), (10, 23), (11, 24), (12, 25), (13, 26), (14, 27), (15, 28), (16, 29), (17, 30), (18, 31), (19, 32), (20, 33), (21, 34), (22, 35), (23, 36), (24, 37), (25, 38), (26, 39), (27, 40), (28, 41), (29, 42), (30, 43), (31, 44), (32, 45), (33, 46), (34, 47), (35, 48), (36, 49), (37, 50), (38, 51), (39, 52), (40, 53), (41, 54), (42, 55), (43, 56), (44, 57), (45, 58), (46, 59), (47, 60), (48, 61), (49, 62), (50, 63), (51, 64), (52, 65), (53, 66), (54, 67), (55, 68), (56, 69), (57, 70), (58, 71), (59, 72), (60, 73), (61, 74), (62, 75), (63, 76), (64, 77), (65, 78), (66, 79), (67, 80), (68, 81), (69, 82), (70, 83), (71, 84), (72, 85), (73, 86), (74, 87), (75, 88), (76, 89), (77, 90), (78, 91), (79, 92), (80, 93), (81, 94), (82, 95), (83, 96), (84, 97), (85, 98), (86, 99), (87, 100), (88, 101), (89, 102), (90, 103), (91, 104), (92, 105), (93, 106), (94, 107), (95, 108), (96, 109), (97, 110), (98, 111), (99, 112), (100, 113), (101, 114), (102, 115), (103, 116), (104, 117), (105, 118), (106, 119), (107, 120), (108, 121), (109, 122), (110, 123), (111, 124), (112, 125), (113, 126), (114, 127), (115, 128), (116, 129), (117, 130), (118, 131), (119, 132), (120, 133), (121, 134), (122, 135), (123, 136), (124, 137), (125, 138), (126, 139), (127, 140), (128, 141), (129, 142), (130, 143), (131, 144), (132, 145), (133, 146), (134, 147), (135, 148), (136, 149), (137, 150), (138, 151), (139, 152), (140, 153), (141, 154), (142, 155), (143, 156), (144, 157), (145, 158), (146, 159), (147, 160), (148, 161), (149, 162), (150, 163), (151, 164), (152, 165), (153, 166), (154, 167), (155, 168), (156, 169), (157, 170), (158, 171), (159, 172), (160, 173), (161, 174), (162, 175), (163, 176), (164, 177), (165, 178), (166, 179), (167, 180), (168, 181), (169, 182), (170, 183), (171, 184), (172, 185), (173, 186), (174, 187), (175, 188), (176, 189), (177, 190), (178, 191), (179, 192), (180, 193), (181, 194), (182, 195), (183, 196), (184, 197), (185, 198), (186, 199), (187, 200), (188, 201), (189, 202), (190, 203), (191, 204), (192, 205), (193, 206), (194, 207), (195, 208), (196, 209), (197, 210), (198, 211), (199, 212), (200, 213), (201, 214), (202, 215), (203, 216), (204, 217), (205, 218), (206, 219), (207, 220), (208, 221), (209, 222), (210, 223), (211, 224), (212, 225), (213, 226), (214, 227), (215, 228), (216, 229), (217, 230), (218, 231), (219, 232), (220, 233), (221, 234), (222, 235), (223, 236), (224, 237), (225, 238), (226, 239), (227, 240), (228, 241), (229, 242), (230, 243), (231, 244), (232, 245), (233, 246), (234, 247), (235, 248), (236, 249), (237, 250), (238, 251), (239, 252), (240, 253), (241, 254), (242, 255), (243, 256), (244, 257), (245, 258), (246, 259), (247, 260), (248, 261), (249, 262), (250, 263), (251, 264), (252, 265), (253, 266), (254, 267), (255, 268), (256, 269), (257, 270), (258, 271), (259, 272), (260, 273), (261, 274), (262, 275), (263, 276), (264, 277), (265, 278), (266, 279), (267, 280), (268, 281), (269, 282), (270, 283), (271, 284), (272, 285), (273, 286), (274, 287), (275, 288), (276, 289), (277, 290), (278, 291), (279, 292), (280, 293), (281, 294), (282, 295), (283, 296), (284, 297), (285, 298), (286, 299), (287, 300), (288, 301), (289, 302), (290, 303), (291, 304), (292, 305), (293, 306), (294, 307), (295, 308), (296, 309), (297, 310), (298, 311), (299, 312), (300, 313), (301, 314), (302, 315), (303, 316), (304, 317), (305, 318), (306, 319), (307, 320), (308, 321), (309, 322), (310, 323), (311, 324), (312, 325), (313, 326), (314, 327), (315, 328), (316, 329), (317, 330), (318, 331), (319, 332), (320, 333), (321, 334), (322, 335), (323, 336), (324, 337), (325, 338), (326, 339), (327, 340), (328, 341), (329, 342), (330, 343), (331, 344), (332, 345), (333, 346), (334, 347), (335, 348), (336, 349), (337, 350), (338, 351), (339, 352), (340, 353), (341, 354), (342, 355), (343, 356), (344, 357), (345, 358), (346, 359), (347, 360), (348, 361), (349, 362), (350, 363), (351, 364), (352, 365), (353, 366), (354, 367), (355, 368), (356, 369), (357, 370), (358, 371), (359, 372), (360, 373), (361, 374), (362, 375), (363, 376), (364, 377), (365, 378), (366, 379), (367, 380), (368, 381), (369, 382), (370, 383), (371, 384), (372, 385), (373, 386), (374, 387), (375, 388), (376, 389), (377, 390), (378, 391), (379, 392), (380, 393), (381, 394), (382, 395), (383, 396), (384, 397), (385, 398), (386, 399), (387, 400), (388, 401), (389, 402), (390, 403), (391, 404), (392, 405), (393, 406), (394, 407), (395, 408), (396, 409), (397, 410), (398, 411), (399, 412), (400, 413), (401, 414), (402, 415), (403, 416), (404, 417), (405, 418), (406, 419), (407, 420), (408, 421), (409, 422), (410, 423), (411, 424), (412, 425), (413, 426), (414, 427), (415, 428), (416, 429), (417, 430), (418, 431), (419, 432), (420, 433), (421, 434), (422, 435), (423, 436), (424, 437), (425, 438), (426, 439), (427, 440), (428, 441), (429, 442), (430, 443), (431, 444), (432, 445), (433, 446), (434, 447), (435, 448), (436, 449), (437, 450), (438, 451), (439, 452), (440, 453), (441, 454), (442, 455), (443, 456), (444, 457), (445, 458), (446, 459), (447, 460), (448, 461), (449, 462), (450, 463), (451, 464), (452, 465), (453, 466), (454, 467), (455, 468), (456, 469), (457, 470), (458, 471), (459, 472), (460, 473), (461, 474), (462, 475), (463, 476), (464, 477), (465, 478), (466, 479), (467, 480), (468, 481), (469, 482), (470, 483), (471, 484), (472, 485), (473, 486), (474, 487), (475, 488), (476, 489), (477, 490), (478, 491), (479, 492), (480, 493), (481, 494), (482, 495), (483, 496), (484, 497), (485, 498), (486, 499), (487, 500), (488, 501), (489, 502), (490, 503), (491, 504), (492, 505), (493, 506), (494, 507), (495, 508), (496, 509), (497, 510), (498, 511), (499, 512), (500, 513), (501, 514), (502, 515), (503, 516), (504, 517), (505, 518), (506, 519), (507, 520), (508, 521), (509, 522), (510, 523), (511, 524), (512, 525), (513, 526), (514, 527), (515, 528), (516, 529), (517, 530), (518, 531), (519, 532), (520, 533), (521, 534), (522, 535), (523, 536), (524, 537), (525, 538), (526, 539), (527, 540), (528, 541), (529, 542), (530, 543), (531, 544), (532, 545), (533, 546), (534, 547), (535, 548), (536, 549), (537, 550), (538, 551), (539, 552), (540, 553), (541, 554), (542, 555), (543, 556), (544, 557), (545, 558), (546, 559), (547, 560), (548, 561), (549, 562), (550, 563), (551, 564), (552, 565), (553, 566), (554, 567), (555, 568), (556, 569), (557, 570), (558, 571), (559, 572), (560, 573), (561, 574), (562, 575), (563, 576), (564, 577), (565, 578), (566, 579), (567, 580), (568, 581), (569, 582), (570, 583), (571, 584), (572, 585), (573, 586), (574, 587), (575, 588), (576, 589), (577, 590), (578, 591), (579, 592), (580, 593), (581, 594), (582, 595), (583, 596), (584, 597), (585, 598), (586, 599), (587, 600), (588, 601), (589, 602), (590, 603), (591, 604), (592, 605), (593, 606), (594, 607), (595, 608), (596, 609), (597, 610), (598, 611), (599, 612), (600, 613), (601, 614), (602, 615), (603, 616), (604, 617), (605, 618), (606, 619), (607, 620), (608, 621), (609, 622), (610, 623), (611, 624), (612, 625), (613, 626), (614, 627), (615, 628), (616, 629), (617, 630), (618, 631), (619, 632), (620, 633), (621, 634), (622, 635), (623, 636), (624, 637), (625, 638), (626, 639), (627, 640), (628, 641), (629, 642), (630, 643), (631, 644), (632, 645), (633, 646), (634, 647), (635, 648), (636, 649), (637, 650), (638, 651), (639, 652), (640, 653), (641, 654), (642, 655), (643, 656), (644, 657), (645, 658), (646, 659), (647, 660), (648, 661), (649, 662), (650, 663), (651, 664), (652, 665), (653, 666), (654, 667), (655, 668), (656, 669), (657, 670), (658, 671), (659, 672), (660, 673), (661, 674), (662, 675), (663, 676), (664, 677), (665, 678), (666, 679), (667, 680), (668, 681), (669, 682), (670, 683), (671, 684), (672, 685), (673, 686), (674, 687), (675, 688), (676, 689), (677, 690), (678, 691), (679, 692), (680, 693), (681, 694), (682, 695), (683, 696), (684, 697), (685, 698), (686, 699), (687, 700), (688, 701), (689, 702), (690, 703), (691, 704), (692, 705), (693, 706), (694, 707), (695, 708), (696, 709), (697, 710), (698, 711), (699, 712), (700, 713), (701, 714), (702, 715), (703, 716), (704, 717), (705, 718), (706, 719), (707, 720), (708, 721), (709, 722), (710, 723), (711, 724), (712, 725), (713, 726), (714, 727), (715, 728), (716, 729), (717, 730), (718, 731)]\n",
      "Number of sequences/examples: 718\n",
      "Last val: 172.82666666666665\n",
      "Target val: 173.19\n",
      "\n",
      "Confirm number of examples: True\n",
      "Num-features-in-each-day: 16\n",
      "N-previous-days: 12\n",
      "Step-size: 1\n",
      "Features shape: (718, 13, 16)\n",
      "Targets shape: (718,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 5.6696984e+07,  1.6474319e+02,  1.6321001e+02, ...,\n",
       "          1.6535001e+02,  7.1554177e-02,  0.0000000e+00],\n",
       "        [ 5.6696984e+07,  1.6474319e+02,  1.6321001e+02, ...,\n",
       "          1.6535001e+02,  7.1554177e-02,  0.0000000e+00],\n",
       "        [ 5.6696984e+07,  1.6474319e+02,  1.6321001e+02, ...,\n",
       "          1.6535001e+02,  7.1554177e-02,  0.0000000e+00],\n",
       "        ...,\n",
       "        [ 6.8039384e+07,  1.7107539e+02,  1.6982001e+02, ...,\n",
       "          1.6647890e+02,  3.0757976e+00,  2.1425605e-02],\n",
       "        [ 6.3390152e+07,  1.7159207e+02,  1.7038667e+02, ...,\n",
       "          1.6704884e+02,  3.0654938e+00,  2.1111756e-03],\n",
       "        [ 5.8740924e+07,  1.7210873e+02,  1.7095334e+02, ...,\n",
       "          1.6759911e+02,  2.0051730e+00,  2.1067280e-03]],\n",
       "\n",
       "       [[ 5.6696984e+07,  1.6474319e+02,  1.6321001e+02, ...,\n",
       "          1.6535001e+02,  7.1554177e-02,  0.0000000e+00],\n",
       "        [ 5.6696984e+07,  1.6474319e+02,  1.6321001e+02, ...,\n",
       "          1.6535001e+02,  7.1554177e-02,  0.0000000e+00],\n",
       "        [ 5.6696984e+07,  1.6474319e+02,  1.6321001e+02, ...,\n",
       "          1.6535001e+02,  7.1554177e-02,  0.0000000e+00],\n",
       "        ...,\n",
       "        [ 6.3390152e+07,  1.7159207e+02,  1.7038667e+02, ...,\n",
       "          1.6704884e+02,  3.0654938e+00,  2.1111756e-03],\n",
       "        [ 5.8740924e+07,  1.7210873e+02,  1.7095334e+02, ...,\n",
       "          1.6759911e+02,  2.0051730e+00,  2.1067280e-03],\n",
       "        [ 5.4091696e+07,  1.7262540e+02,  1.7152000e+02, ...,\n",
       "          1.6813158e+02,  1.9020565e+00,  2.1022991e-03]],\n",
       "\n",
       "       [[ 5.6696984e+07,  1.6474319e+02,  1.6321001e+02, ...,\n",
       "          1.6535001e+02,  7.1554177e-02,  0.0000000e+00],\n",
       "        [ 5.6696984e+07,  1.6474319e+02,  1.6321001e+02, ...,\n",
       "          1.6535001e+02,  7.1554177e-02,  0.0000000e+00],\n",
       "        [ 5.7918768e+07,  1.6512677e+02,  1.6426334e+02, ...,\n",
       "          1.6533476e+02,  7.1554177e-02, -9.6764439e-04],\n",
       "        ...,\n",
       "        [ 5.8740924e+07,  1.7210873e+02,  1.7095334e+02, ...,\n",
       "          1.6759911e+02,  2.0051730e+00,  2.1067280e-03],\n",
       "        [ 5.4091696e+07,  1.7262540e+02,  1.7152000e+02, ...,\n",
       "          1.6813158e+02,  1.9020565e+00,  2.1022991e-03],\n",
       "        [ 5.6377048e+07,  1.7274271e+02,  1.7278000e+02, ...,\n",
       "          1.6859810e+02,  4.4120163e-01, -9.2384085e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 5.5878904e+07,  2.2883960e+02,  2.2945000e+02, ...,\n",
       "          2.2596083e+02,  2.3910267e+00, -2.5295971e-02],\n",
       "        [ 6.4346032e+07,  2.2518100e+02,  2.3028000e+02, ...,\n",
       "          2.2579123e+02,  4.5164819e+00, -2.0534778e-02],\n",
       "        [ 4.8020040e+07,  2.2473560e+02,  2.2482001e+02, ...,\n",
       "          2.2565015e+02,  5.1906090e+00,  5.7989114e-04],\n",
       "        ...,\n",
       "        [ 3.8269672e+07,  2.1797676e+02,  2.1812000e+02, ...,\n",
       "          2.2283679e+02,  3.1522350e+00,  4.2821313e-04],\n",
       "        [ 3.6711700e+07,  2.1805434e+02,  2.1753999e+02, ...,\n",
       "          2.2239012e+02,  3.7763593e-01,  4.2802983e-04],\n",
       "        [ 3.5153728e+07,  2.1813190e+02,  2.1696001e+02, ...,\n",
       "          2.2199487e+02,  2.9207686e-01,  4.2784671e-04]],\n",
       "\n",
       "       [[ 6.4346032e+07,  2.2518100e+02,  2.3028000e+02, ...,\n",
       "          2.2579123e+02,  4.5164819e+00, -2.0534778e-02],\n",
       "        [ 4.8020040e+07,  2.2473560e+02,  2.2482001e+02, ...,\n",
       "          2.2565015e+02,  5.1906090e+00,  5.7989114e-04],\n",
       "        [ 4.6999404e+07,  2.2482990e+02,  2.2555000e+02, ...,\n",
       "          2.2551141e+02,  4.6735950e+00, -5.2011351e-04],\n",
       "        ...,\n",
       "        [ 3.6711700e+07,  2.1805434e+02,  2.1753999e+02, ...,\n",
       "          2.2239012e+02,  3.7763593e-01,  4.2802983e-04],\n",
       "        [ 3.5153728e+07,  2.1813190e+02,  2.1696001e+02, ...,\n",
       "          2.2199487e+02,  2.9207686e-01,  4.2784671e-04],\n",
       "        [ 4.0681624e+07,  2.1840590e+02,  2.1919000e+02, ...,\n",
       "          2.2169060e+02,  3.2998317e-01,  2.5659825e-03]],\n",
       "\n",
       "       [[ 4.8020040e+07,  2.2473560e+02,  2.2482001e+02, ...,\n",
       "          2.2565015e+02,  5.1906090e+00,  5.7989114e-04],\n",
       "        [ 4.6999404e+07,  2.2482990e+02,  2.2555000e+02, ...,\n",
       "          2.2551141e+02,  4.6735950e+00, -5.2011351e-04],\n",
       "        [ 4.5978772e+07,  2.2492419e+02,  2.2628000e+02, ...,\n",
       "          2.2537477e+02,  2.0990615e+00, -5.2038417e-04],\n",
       "        ...,\n",
       "        [ 3.5153728e+07,  2.1813190e+02,  2.1696001e+02, ...,\n",
       "          2.2199487e+02,  2.9207686e-01,  4.2784671e-04],\n",
       "        [ 4.0681624e+07,  2.1840590e+02,  2.1919000e+02, ...,\n",
       "          2.2169060e+02,  3.2998317e-01,  2.5659825e-03],\n",
       "        [ 4.8422976e+07,  2.2234410e+02,  2.2144000e+02, ...,\n",
       "          2.2172768e+02,  1.7108387e+00,  1.4990860e-02]]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (number_of_sequences, sequence_length, number_of_features)\n",
    "# each sequence is an example, seq_len is number of days in each example, features is values per day\n",
    "# number of cutoff indicies is each example\n",
    "# for each cutoff indicies-pair get those days, create a matrix for each day add those days features as a row\n",
    "# then add this matrix for this sequence to the total matrix as a single example\n",
    "def transform_ts_data_into_features_target(ts_prices, n_previous_days, step_size):\n",
    "    indicies = get_cutoff_indicies(ts_prices, n_previous_days, step_size)\n",
    "    indicies = indicies[:len(indicies)-1]  # exclude last pair\n",
    "    num_seqs = len(indicies)\n",
    "    print(f\"Number of sequences/examples: {num_seqs}\")\n",
    "\n",
    "    features = []  \n",
    "    targets = []\n",
    "\n",
    "    for pair in indicies:\n",
    "        start_indx = pair[0]  # start-index of day-row to end-index of day-row, all days in between this range is a sequence/example\n",
    "        end_indx = pair[1]  # target indx of row\n",
    "\n",
    "        sequence_df = ts_prices.iloc[start_indx: end_indx]  # get day-rows from start-indx to just before end-indx, each element is a day in current-sequence-day-example\n",
    "\n",
    "        cur_seq_days_matrix = []  # each row is the values of features for each day in cur-sequence-example\n",
    "        for _, day_row in sequence_df.iterrows():\n",
    "            \n",
    "            values = list(day_row.drop(labels=\"datetime\").values)\n",
    "            cur_seq_days_matrix.append(values)\n",
    "\n",
    "        features.append(cur_seq_days_matrix)\n",
    "        target_value = ts_prices.iloc[end_indx][\"close_price\"]   # target row is end-indx close-price\n",
    "        targets.append(target_value)\n",
    "\n",
    "        if pair == indicies[0]: # confirm last-val of seq is not same as the target next value\n",
    "            print(f\"Last val: {sequence_df.iloc[-1][\"close_price\"]}\")\n",
    "            print(f\"Target val: {target_value}\")\n",
    "\n",
    "    features = np.array(features, dtype=np.float32)\n",
    "    targets = np.array(targets, dtype=np.float32)\n",
    "    return features, targets\n",
    "\n",
    "print(indicies)\n",
    "features, targets = transform_ts_data_into_features_target(ts_prices, n_previous_days, step_size)\n",
    "print(f\"\\nConfirm number of examples: {len(features) == len(targets)}\")\n",
    "print(f\"Num-features-in-each-day: {len(ts_prices.columns)-1}\")\n",
    "print(f\"N-previous-days: {n_previous_days}\")\n",
    "print(f\"Step-size: {step_size}\")\n",
    "print(f'Features shape: {features.shape}')  # Should be (number_of_examples, n_previous_days, n_features)\n",
    "print(f'Targets shape: {targets.shape}')    # Should be (number_of_examples,)\n",
    "features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 27380.8496 - val_loss: 33454.0781\n",
      "Epoch 2/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 24665.2969 - val_loss: 32442.2227\n",
      "Epoch 3/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 23719.2246 - val_loss: 31719.1211\n",
      "Epoch 4/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 23282.9473 - val_loss: 31036.6074\n",
      "Epoch 5/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 22562.7578 - val_loss: 30381.8047\n",
      "Epoch 6/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 21940.9414 - val_loss: 29747.9199\n",
      "Epoch 7/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 21327.9980 - val_loss: 29131.3535\n",
      "Epoch 8/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 20856.7695 - val_loss: 28528.5938\n",
      "Epoch 9/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 20626.6191 - val_loss: 27938.0547\n",
      "Epoch 10/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 19774.4258 - val_loss: 27362.1250\n",
      "Epoch 11/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 19329.0664 - val_loss: 26796.6152\n",
      "Epoch 12/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 18754.0312 - val_loss: 26243.2344\n",
      "Epoch 13/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 19032.5938 - val_loss: 25696.2188\n",
      "Epoch 14/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 18074.9316 - val_loss: 25162.8496\n",
      "Epoch 15/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 17618.8105 - val_loss: 24638.4629\n",
      "Epoch 16/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 17269.0977 - val_loss: 24124.4883\n",
      "Epoch 17/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 16511.4629 - val_loss: 23621.2422\n",
      "Epoch 18/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 16235.9824 - val_loss: 23124.6523\n",
      "Epoch 19/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 15630.8164 - val_loss: 22637.4434\n",
      "Epoch 20/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 15334.2236 - val_loss: 22158.9746\n",
      "Epoch 21/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 14937.8750 - val_loss: 21689.9609\n",
      "Epoch 22/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 14955.8242 - val_loss: 21228.2480\n",
      "Epoch 23/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 14354.8379 - val_loss: 20775.7852\n",
      "Epoch 24/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 13813.3018 - val_loss: 20331.4375\n",
      "Epoch 25/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 13716.5908 - val_loss: 19895.0234\n",
      "Epoch 26/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 12838.7266 - val_loss: 19468.5195\n",
      "Epoch 27/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 12911.1895 - val_loss: 19047.1699\n",
      "Epoch 28/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 12342.9609 - val_loss: 18634.5586\n",
      "Epoch 29/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 12189.5957 - val_loss: 18229.0664\n",
      "Epoch 30/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 11778.8877 - val_loss: 17830.3770\n",
      "Epoch 31/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 11716.5342 - val_loss: 17439.7910\n",
      "Epoch 32/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 11509.1006 - val_loss: 17056.8125\n",
      "Epoch 33/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - loss: 10844.3047 - val_loss: 16681.5449\n",
      "Epoch 34/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 10617.7783 - val_loss: 16312.8799\n",
      "Epoch 35/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 10170.0146 - val_loss: 15951.4824\n",
      "Epoch 36/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 10279.3125 - val_loss: 15596.0352\n",
      "Epoch 37/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 9996.2695 - val_loss: 15247.3389\n",
      "Epoch 38/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 9586.3359 - val_loss: 14906.1768\n",
      "Epoch 39/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 9330.9473 - val_loss: 14571.6182\n",
      "Epoch 40/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 9269.2100 - val_loss: 14242.6143\n",
      "Epoch 41/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 8708.8242 - val_loss: 13921.3350\n",
      "Epoch 42/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 8428.8262 - val_loss: 13605.9287\n",
      "Epoch 43/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - loss: 8173.8550 - val_loss: 13297.3467\n",
      "Epoch 44/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 7902.7798 - val_loss: 12994.3105\n",
      "Epoch 45/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 7695.8882 - val_loss: 12697.0645\n",
      "Epoch 46/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 7486.1304 - val_loss: 12405.9824\n",
      "Epoch 47/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 7200.8789 - val_loss: 12121.2432\n",
      "Epoch 48/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 7140.7295 - val_loss: 11840.5225\n",
      "Epoch 49/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 6829.9482 - val_loss: 11567.0869\n",
      "Epoch 50/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 6665.8071 - val_loss: 11298.5137\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
      "[173.19 173.03 174.55 174.15 171.52]\n",
      "[[89.43906 ]\n",
      " [89.43925 ]\n",
      " [89.43911 ]\n",
      " [89.438835]\n",
      " [89.43927 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "\n",
    "X = features\n",
    "Y = targets\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(units=500, return_sequences=True, input_shape=(X.shape[1], X.shape[2]))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=100))\n",
    "model.add(Dense(1))  # Output layer for a single prediction\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "history = model.fit(X, Y, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Example: print the first few predictions\n",
    "print(targets[:5])\n",
    "print(predictions[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 27855.9297 - val_loss: 35761.6055\n",
      "Epoch 2/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26338.2363 - val_loss: 35462.0352\n",
      "Epoch 3/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26501.5879 - val_loss: 35234.0039\n",
      "Epoch 4/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26351.5586 - val_loss: 35010.3125\n",
      "Epoch 5/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 25916.1660 - val_loss: 34794.9922\n",
      "Epoch 6/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 25841.7402 - val_loss: 34581.2891\n",
      "Epoch 7/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 25579.7070 - val_loss: 34369.9375\n",
      "Epoch 8/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 25239.7871 - val_loss: 34160.5508\n",
      "Epoch 9/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 24942.5215 - val_loss: 33953.1914\n",
      "Epoch 10/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 24866.7090 - val_loss: 33747.3750\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "[173.19 173.03 174.55 174.15 171.52]\n",
      "[[11.080808]\n",
      " [11.080847]\n",
      " [11.080808]\n",
      " [11.080547]\n",
      " [11.080947]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=200, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
    "model.add(SimpleRNN(units=30))  # Second RNN layer\n",
    "model.add(Dense(1))  # Output layer for a single prediction\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "history = model.fit(X, Y, epochs=10, batch_size=32, validation_split=0.2)\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Example: print the first few predictions\n",
    "print(targets[:5])\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 11466225745920.0000 - val_loss: 120989843456.0000\n",
      "Epoch 2/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 545691303936.0000 - val_loss: 97549475840.0000\n",
      "Epoch 3/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 205032194048.0000 - val_loss: 63243702272.0000\n",
      "Epoch 4/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134468894720.0000 - val_loss: 33402406912.0000\n",
      "Epoch 5/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 109841645568.0000 - val_loss: 26705999872.0000\n",
      "Epoch 6/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67288469504.0000 - val_loss: 21091784704.0000\n",
      "Epoch 7/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59421011968.0000 - val_loss: 17465876480.0000\n",
      "Epoch 8/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51383001088.0000 - val_loss: 16934579200.0000\n",
      "Epoch 9/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60991053824.0000 - val_loss: 16292602880.0000\n",
      "Epoch 10/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48572076032.0000 - val_loss: 16984855552.0000\n",
      "Epoch 11/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29591840768.0000 - val_loss: 14600220672.0000\n",
      "Epoch 12/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 37368799232.0000 - val_loss: 20443451392.0000\n",
      "Epoch 13/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 36261953536.0000 - val_loss: 11805627392.0000\n",
      "Epoch 14/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32457207808.0000 - val_loss: 10656885760.0000\n",
      "Epoch 15/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20432748544.0000 - val_loss: 9574043648.0000\n",
      "Epoch 16/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22955319296.0000 - val_loss: 9360335872.0000\n",
      "Epoch 17/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26209476608.0000 - val_loss: 9531034624.0000\n",
      "Epoch 18/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14864517120.0000 - val_loss: 7520033792.0000\n",
      "Epoch 19/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17888045056.0000 - val_loss: 9159414784.0000\n",
      "Epoch 20/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16798608384.0000 - val_loss: 5622111232.0000\n",
      "Epoch 21/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22184998912.0000 - val_loss: 6221606912.0000\n",
      "Epoch 22/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13722253312.0000 - val_loss: 8882548736.0000\n",
      "Epoch 23/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17445079040.0000 - val_loss: 4763885568.0000\n",
      "Epoch 24/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10745368576.0000 - val_loss: 3983118848.0000\n",
      "Epoch 25/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11182084096.0000 - val_loss: 5911627776.0000\n",
      "Epoch 26/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10987766784.0000 - val_loss: 6068121600.0000\n",
      "Epoch 27/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12010419200.0000 - val_loss: 4905905152.0000\n",
      "Epoch 28/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12134535168.0000 - val_loss: 2905893632.0000\n",
      "Epoch 29/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8779732992.0000 - val_loss: 5284665344.0000\n",
      "Epoch 30/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11903956992.0000 - val_loss: 6841301504.0000\n",
      "Epoch 31/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7128991232.0000 - val_loss: 3976492288.0000\n",
      "Epoch 32/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8524434944.0000 - val_loss: 3825093376.0000\n",
      "Epoch 33/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8505453568.0000 - val_loss: 2484197632.0000\n",
      "Epoch 34/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7331917312.0000 - val_loss: 5264790016.0000\n",
      "Epoch 35/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5765924352.0000 - val_loss: 3150695168.0000\n",
      "Epoch 36/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6288758784.0000 - val_loss: 2043576576.0000\n",
      "Epoch 37/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4747463680.0000 - val_loss: 1867002624.0000\n",
      "Epoch 38/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5323641856.0000 - val_loss: 1890182912.0000\n",
      "Epoch 39/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4629021184.0000 - val_loss: 2763572224.0000\n",
      "Epoch 40/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5013648896.0000 - val_loss: 2766917376.0000\n",
      "Epoch 41/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5154181120.0000 - val_loss: 1388653568.0000\n",
      "Epoch 42/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7605320192.0000 - val_loss: 1747993216.0000\n",
      "Epoch 43/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4829561344.0000 - val_loss: 1948490624.0000\n",
      "Epoch 44/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5163238912.0000 - val_loss: 2125535488.0000\n",
      "Epoch 45/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7324742144.0000 - val_loss: 1094054528.0000\n",
      "Epoch 46/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5442856960.0000 - val_loss: 1937408896.0000\n",
      "Epoch 47/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4904126976.0000 - val_loss: 837211648.0000\n",
      "Epoch 48/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5503802368.0000 - val_loss: 729088512.0000\n",
      "Epoch 49/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3444638464.0000 - val_loss: 2244561920.0000\n",
      "Epoch 50/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3955582976.0000 - val_loss: 1046166848.0000\n",
      "Epoch 51/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4809341440.0000 - val_loss: 2091771904.0000\n",
      "Epoch 52/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4384939520.0000 - val_loss: 989800576.0000\n",
      "Epoch 53/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3750280960.0000 - val_loss: 2040530432.0000\n",
      "Epoch 54/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2662582784.0000 - val_loss: 795898944.0000\n",
      "Epoch 55/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2432225024.0000 - val_loss: 1719439360.0000\n",
      "Epoch 56/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2981854208.0000 - val_loss: 538124672.0000\n",
      "Epoch 57/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2849705472.0000 - val_loss: 1099532544.0000\n",
      "Epoch 58/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2821385728.0000 - val_loss: 599545600.0000\n",
      "Epoch 59/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2817955072.0000 - val_loss: 1981355520.0000\n",
      "Epoch 60/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3982554112.0000 - val_loss: 780930752.0000\n",
      "Epoch 61/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1785633920.0000 - val_loss: 964255424.0000\n",
      "Epoch 62/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2706400768.0000 - val_loss: 676608640.0000\n",
      "Epoch 63/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2233515264.0000 - val_loss: 3661903104.0000\n",
      "Epoch 64/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3770854400.0000 - val_loss: 1912585984.0000\n",
      "Epoch 65/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2564499200.0000 - val_loss: 1068370368.0000\n",
      "Epoch 66/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2742051840.0000 - val_loss: 606762880.0000\n",
      "Epoch 67/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2308863744.0000 - val_loss: 312752896.0000\n",
      "Epoch 68/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2304427520.0000 - val_loss: 386585184.0000\n",
      "Epoch 69/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1501244416.0000 - val_loss: 416720864.0000\n",
      "Epoch 70/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2275243264.0000 - val_loss: 1065904128.0000\n",
      "Epoch 71/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1849730432.0000 - val_loss: 231241952.0000\n",
      "Epoch 72/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1720833536.0000 - val_loss: 619952512.0000\n",
      "Epoch 73/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1481125120.0000 - val_loss: 490226560.0000\n",
      "Epoch 74/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1649156608.0000 - val_loss: 178663376.0000\n",
      "Epoch 75/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1632642816.0000 - val_loss: 384501056.0000\n",
      "Epoch 76/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2769066240.0000 - val_loss: 804307520.0000\n",
      "Epoch 77/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1217158272.0000 - val_loss: 257068480.0000\n",
      "Epoch 78/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1629271296.0000 - val_loss: 374471456.0000\n",
      "Epoch 79/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1107538176.0000 - val_loss: 244763584.0000\n",
      "Epoch 80/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1351614464.0000 - val_loss: 240653056.0000\n",
      "Epoch 81/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1968591872.0000 - val_loss: 229598608.0000\n",
      "Epoch 82/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1859087616.0000 - val_loss: 578540416.0000\n",
      "Epoch 83/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1491262464.0000 - val_loss: 819994432.0000\n",
      "Epoch 84/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1990359040.0000 - val_loss: 401377984.0000\n",
      "Epoch 85/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1726049792.0000 - val_loss: 574529280.0000\n",
      "Epoch 86/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1952187008.0000 - val_loss: 527056832.0000\n",
      "Epoch 87/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1479031808.0000 - val_loss: 372513632.0000\n",
      "Epoch 88/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1019676416.0000 - val_loss: 365476800.0000\n",
      "Epoch 89/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1343750912.0000 - val_loss: 667624000.0000\n",
      "Epoch 90/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1155449856.0000 - val_loss: 176590624.0000\n",
      "Epoch 91/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1030688832.0000 - val_loss: 300168000.0000\n",
      "Epoch 92/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 947483456.0000 - val_loss: 130236128.0000\n",
      "Epoch 93/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 915897280.0000 - val_loss: 174011552.0000\n",
      "Epoch 94/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 722503808.0000 - val_loss: 334107200.0000\n",
      "Epoch 95/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 794449152.0000 - val_loss: 188393920.0000\n",
      "Epoch 96/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1029832960.0000 - val_loss: 89678176.0000\n",
      "Epoch 97/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 740170880.0000 - val_loss: 314219744.0000\n",
      "Epoch 98/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 889923008.0000 - val_loss: 477521920.0000\n",
      "Epoch 99/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1107651712.0000 - val_loss: 782337856.0000\n",
      "Epoch 100/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1291671936.0000 - val_loss: 581889920.0000\n",
      "Epoch 101/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 923949184.0000 - val_loss: 1016887296.0000\n",
      "Epoch 102/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1032472704.0000 - val_loss: 118296936.0000\n",
      "Epoch 103/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 567588480.0000 - val_loss: 108729696.0000\n",
      "Epoch 104/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 706500032.0000 - val_loss: 497829664.0000\n",
      "Epoch 105/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1579040896.0000 - val_loss: 191546048.0000\n",
      "Epoch 106/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 857401344.0000 - val_loss: 573734848.0000\n",
      "Epoch 107/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1275557632.0000 - val_loss: 117861688.0000\n",
      "Epoch 108/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1450242816.0000 - val_loss: 184449472.0000\n",
      "Epoch 109/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 657597824.0000 - val_loss: 553870208.0000\n",
      "Epoch 110/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 812146624.0000 - val_loss: 53552468.0000\n",
      "Epoch 111/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 991284096.0000 - val_loss: 235865280.0000\n",
      "Epoch 112/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 855412672.0000 - val_loss: 470156672.0000\n",
      "Epoch 113/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 798090048.0000 - val_loss: 57186924.0000\n",
      "Epoch 114/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 481448480.0000 - val_loss: 283020480.0000\n",
      "Epoch 115/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1073276480.0000 - val_loss: 744849600.0000\n",
      "Epoch 116/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 661800256.0000 - val_loss: 2659436032.0000\n",
      "Epoch 117/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1705777152.0000 - val_loss: 68241656.0000\n",
      "Epoch 118/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 494279520.0000 - val_loss: 708364416.0000\n",
      "Epoch 119/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 605527232.0000 - val_loss: 824844800.0000\n",
      "Epoch 120/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1139812736.0000 - val_loss: 228502112.0000\n",
      "Epoch 121/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 650589120.0000 - val_loss: 245616560.0000\n",
      "Epoch 122/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 598824128.0000 - val_loss: 63357176.0000\n",
      "Epoch 123/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 645204288.0000 - val_loss: 514785664.0000\n",
      "Epoch 124/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1147587584.0000 - val_loss: 461785568.0000\n",
      "Epoch 125/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 754949312.0000 - val_loss: 26488186.0000\n",
      "Epoch 126/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 447247488.0000 - val_loss: 1110298624.0000\n",
      "Epoch 127/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 988771520.0000 - val_loss: 446768064.0000\n",
      "Epoch 128/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 666118592.0000 - val_loss: 47489376.0000\n",
      "Epoch 129/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 239941392.0000 - val_loss: 195704512.0000\n",
      "Epoch 130/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 331809600.0000 - val_loss: 175433408.0000\n",
      "Epoch 131/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 325748960.0000 - val_loss: 124205352.0000\n",
      "Epoch 132/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 429794944.0000 - val_loss: 189291216.0000\n",
      "Epoch 133/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 366555840.0000 - val_loss: 32579062.0000\n",
      "Epoch 134/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 510308448.0000 - val_loss: 25638360.0000\n",
      "Epoch 135/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 323556160.0000 - val_loss: 21827372.0000\n",
      "Epoch 136/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 231721312.0000 - val_loss: 29291432.0000\n",
      "Epoch 137/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 632311424.0000 - val_loss: 33488626.0000\n",
      "Epoch 138/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 344825344.0000 - val_loss: 25100662.0000\n",
      "Epoch 139/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 360948928.0000 - val_loss: 389692064.0000\n",
      "Epoch 140/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 414189376.0000 - val_loss: 233683296.0000\n",
      "Epoch 141/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 371149792.0000 - val_loss: 26671044.0000\n",
      "Epoch 142/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 222416672.0000 - val_loss: 41068956.0000\n",
      "Epoch 143/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 417380768.0000 - val_loss: 40628652.0000\n",
      "Epoch 144/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 367666944.0000 - val_loss: 616417344.0000\n",
      "Epoch 145/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 882398016.0000 - val_loss: 74669280.0000\n",
      "Epoch 146/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 240373248.0000 - val_loss: 16032619.0000\n",
      "Epoch 147/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 167012176.0000 - val_loss: 220523968.0000\n",
      "Epoch 148/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 437818176.0000 - val_loss: 235472064.0000\n",
      "Epoch 149/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 357517184.0000 - val_loss: 932278464.0000\n",
      "Epoch 150/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 608479296.0000 - val_loss: 19660498.0000\n",
      "Epoch 151/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 287542496.0000 - val_loss: 84726456.0000\n",
      "Epoch 152/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 199202128.0000 - val_loss: 179864000.0000\n",
      "Epoch 153/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 451277248.0000 - val_loss: 209808192.0000\n",
      "Epoch 154/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 390635616.0000 - val_loss: 20048346.0000\n",
      "Epoch 155/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 280839648.0000 - val_loss: 24939488.0000\n",
      "Epoch 156/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 146542720.0000 - val_loss: 70095112.0000\n",
      "Epoch 157/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 218151952.0000 - val_loss: 414569600.0000\n",
      "Epoch 158/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 376919392.0000 - val_loss: 84182880.0000\n",
      "Epoch 159/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 182214496.0000 - val_loss: 10542052.0000\n",
      "Epoch 160/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 236815264.0000 - val_loss: 1193437568.0000\n",
      "Epoch 161/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 645140736.0000 - val_loss: 12429090.0000\n",
      "Epoch 162/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 159693088.0000 - val_loss: 91429232.0000\n",
      "Epoch 163/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 291883744.0000 - val_loss: 72362896.0000\n",
      "Epoch 164/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 524992128.0000 - val_loss: 44667072.0000\n",
      "Epoch 165/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 211085888.0000 - val_loss: 116460448.0000\n",
      "Epoch 166/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 588508992.0000 - val_loss: 708688576.0000\n",
      "Epoch 167/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1708364800.0000 - val_loss: 69192040.0000\n",
      "Epoch 168/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 297239072.0000 - val_loss: 515507776.0000\n",
      "Epoch 169/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 487295040.0000 - val_loss: 822528128.0000\n",
      "Epoch 170/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 508311968.0000 - val_loss: 54561340.0000\n",
      "Epoch 171/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 368510208.0000 - val_loss: 45186224.0000\n",
      "Epoch 172/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 175297376.0000 - val_loss: 596488896.0000\n",
      "Epoch 173/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 508280128.0000 - val_loss: 340003968.0000\n",
      "Epoch 174/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 525796640.0000 - val_loss: 19937084.0000\n",
      "Epoch 175/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 308287808.0000 - val_loss: 505805984.0000\n",
      "Epoch 176/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1359891584.0000 - val_loss: 920989440.0000\n",
      "Epoch 177/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 866109824.0000 - val_loss: 274591264.0000\n",
      "Epoch 178/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 674581696.0000 - val_loss: 2959327488.0000\n",
      "Epoch 179/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1942024448.0000 - val_loss: 288530240.0000\n",
      "Epoch 180/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 610959232.0000 - val_loss: 18938504.0000\n",
      "Epoch 181/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 196682656.0000 - val_loss: 12158482.0000\n",
      "Epoch 182/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 161270528.0000 - val_loss: 13531541.0000\n",
      "Epoch 183/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 95872264.0000 - val_loss: 16093561.0000\n",
      "Epoch 184/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 129139448.0000 - val_loss: 10097551.0000\n",
      "Epoch 185/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 254554528.0000 - val_loss: 80107064.0000\n",
      "Epoch 186/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 179389456.0000 - val_loss: 686408256.0000\n",
      "Epoch 187/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 541093120.0000 - val_loss: 21159556.0000\n",
      "Epoch 188/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 641344256.0000 - val_loss: 492444736.0000\n",
      "Epoch 189/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 544590144.0000 - val_loss: 323180224.0000\n",
      "Epoch 190/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 540156608.0000 - val_loss: 2829214208.0000\n",
      "Epoch 191/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1582776576.0000 - val_loss: 64097408.0000\n",
      "Epoch 192/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 591953472.0000 - val_loss: 189628240.0000\n",
      "Epoch 193/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201612320.0000 - val_loss: 168930080.0000\n",
      "Epoch 194/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 258377936.0000 - val_loss: 9094345.0000\n",
      "Epoch 195/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139785808.0000 - val_loss: 66964516.0000\n",
      "Epoch 196/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 156589696.0000 - val_loss: 105211552.0000\n",
      "Epoch 197/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 256007744.0000 - val_loss: 97600952.0000\n",
      "Epoch 198/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 536016416.0000 - val_loss: 343844832.0000\n",
      "Epoch 199/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 296026784.0000 - val_loss: 21195676.0000\n",
      "Epoch 200/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 227113776.0000 - val_loss: 23470148.0000\n",
      "Epoch 201/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1005948224.0000 - val_loss: 754943424.0000\n",
      "Epoch 202/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 461763584.0000 - val_loss: 49223356.0000\n",
      "Epoch 203/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 627060096.0000 - val_loss: 567106880.0000\n",
      "Epoch 204/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 420257216.0000 - val_loss: 267475008.0000\n",
      "Epoch 205/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 329109760.0000 - val_loss: 16419797.0000\n",
      "Epoch 206/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 168931568.0000 - val_loss: 527893632.0000\n",
      "Epoch 207/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 555727360.0000 - val_loss: 562118272.0000\n",
      "Epoch 208/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1692693120.0000 - val_loss: 424609184.0000\n",
      "Epoch 209/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 367099424.0000 - val_loss: 33880588.0000\n",
      "Epoch 210/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 110981320.0000 - val_loss: 44378308.0000\n",
      "Epoch 211/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 82151192.0000 - val_loss: 103472168.0000\n",
      "Epoch 212/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 244062768.0000 - val_loss: 658838528.0000\n",
      "Epoch 213/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 409702752.0000 - val_loss: 779178624.0000\n",
      "Epoch 214/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 251544512.0000 - val_loss: 332219072.0000\n",
      "Epoch 215/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 236067136.0000 - val_loss: 23838450.0000\n",
      "Epoch 216/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 81644072.0000 - val_loss: 54947040.0000\n",
      "Epoch 217/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 122341208.0000 - val_loss: 195428544.0000\n",
      "Epoch 218/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 437948992.0000 - val_loss: 927096640.0000\n",
      "Epoch 219/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 543981888.0000 - val_loss: 11079563.0000\n",
      "Epoch 220/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 158081360.0000 - val_loss: 27987800.0000\n",
      "Epoch 221/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 119734176.0000 - val_loss: 5822265.0000\n",
      "Epoch 222/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 84692968.0000 - val_loss: 22808920.0000\n",
      "Epoch 223/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121704000.0000 - val_loss: 6549972.5000\n",
      "Epoch 224/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 311448032.0000 - val_loss: 743941504.0000\n",
      "Epoch 225/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 410424768.0000 - val_loss: 42121504.0000\n",
      "Epoch 226/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 184683984.0000 - val_loss: 182635120.0000\n",
      "Epoch 227/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127812592.0000 - val_loss: 241769504.0000\n",
      "Epoch 228/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 477361536.0000 - val_loss: 1174787840.0000\n",
      "Epoch 229/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 503729280.0000 - val_loss: 9639159.0000\n",
      "Epoch 230/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 346093504.0000 - val_loss: 97732592.0000\n",
      "Epoch 231/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147765456.0000 - val_loss: 3311817.0000\n",
      "Epoch 232/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 66833192.0000 - val_loss: 11223820.0000\n",
      "Epoch 233/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 75624616.0000 - val_loss: 8715785.0000\n",
      "Epoch 234/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 174339184.0000 - val_loss: 556620352.0000\n",
      "Epoch 235/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 661215232.0000 - val_loss: 346058752.0000\n",
      "Epoch 236/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 724440832.0000 - val_loss: 164668640.0000\n",
      "Epoch 237/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 215086736.0000 - val_loss: 36351920.0000\n",
      "Epoch 238/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124488256.0000 - val_loss: 145757056.0000\n",
      "Epoch 239/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 315035392.0000 - val_loss: 224523984.0000\n",
      "Epoch 240/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149168496.0000 - val_loss: 42407628.0000\n",
      "Epoch 241/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 159980464.0000 - val_loss: 263354848.0000\n",
      "Epoch 242/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 442605568.0000 - val_loss: 490313888.0000\n",
      "Epoch 243/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 258590096.0000 - val_loss: 24704802.0000\n",
      "Epoch 244/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 92835832.0000 - val_loss: 188464768.0000\n",
      "Epoch 245/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 556002752.0000 - val_loss: 2468601856.0000\n",
      "Epoch 246/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1853220608.0000 - val_loss: 759362112.0000\n",
      "Epoch 247/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 709105216.0000 - val_loss: 19180744.0000\n",
      "Epoch 248/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 124198680.0000 - val_loss: 301590048.0000\n",
      "Epoch 249/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 203623232.0000 - val_loss: 76206368.0000\n",
      "Epoch 250/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 96606256.0000 - val_loss: 98963808.0000\n",
      "Epoch 251/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 184072832.0000 - val_loss: 56670552.0000\n",
      "Epoch 252/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 85781552.0000 - val_loss: 113094048.0000\n",
      "Epoch 253/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 82556352.0000 - val_loss: 12226168.0000\n",
      "Epoch 254/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 87481792.0000 - val_loss: 2745005.0000\n",
      "Epoch 255/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 46454888.0000 - val_loss: 10337878.0000\n",
      "Epoch 256/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 179284144.0000 - val_loss: 564934912.0000\n",
      "Epoch 257/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 370798848.0000 - val_loss: 510261184.0000\n",
      "Epoch 258/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 366243584.0000 - val_loss: 16162388.0000\n",
      "Epoch 259/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 179328096.0000 - val_loss: 2489131.0000\n",
      "Epoch 260/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56195324.0000 - val_loss: 16823966.0000\n",
      "Epoch 261/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 97288480.0000 - val_loss: 3818332.0000\n",
      "Epoch 262/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 66643072.0000 - val_loss: 41763888.0000\n",
      "Epoch 263/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131362272.0000 - val_loss: 6937321.0000\n",
      "Epoch 264/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 65919624.0000 - val_loss: 5374555.0000\n",
      "Epoch 265/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 85966704.0000 - val_loss: 55562496.0000\n",
      "Epoch 266/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 138368928.0000 - val_loss: 225588768.0000\n",
      "Epoch 267/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 192669312.0000 - val_loss: 109482656.0000\n",
      "Epoch 268/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 313230144.0000 - val_loss: 98894512.0000\n",
      "Epoch 269/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 659011264.0000 - val_loss: 4342066176.0000\n",
      "Epoch 270/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2441696000.0000 - val_loss: 113538888.0000\n",
      "Epoch 271/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 170415440.0000 - val_loss: 40668660.0000\n",
      "Epoch 272/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 75904168.0000 - val_loss: 75918016.0000\n",
      "Epoch 273/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 268359184.0000 - val_loss: 131334032.0000\n",
      "Epoch 274/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131824496.0000 - val_loss: 21660052.0000\n",
      "Epoch 275/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53456568.0000 - val_loss: 55494768.0000\n",
      "Epoch 276/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 100117288.0000 - val_loss: 21136696.0000\n",
      "Epoch 277/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68416312.0000 - val_loss: 74532680.0000\n",
      "Epoch 278/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114975456.0000 - val_loss: 5096635.0000\n",
      "Epoch 279/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63172952.0000 - val_loss: 103629080.0000\n",
      "Epoch 280/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 188382528.0000 - val_loss: 8841698.0000\n",
      "Epoch 281/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 103279288.0000 - val_loss: 118446648.0000\n",
      "Epoch 282/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 210416944.0000 - val_loss: 43282564.0000\n",
      "Epoch 283/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 49391732.0000 - val_loss: 27381832.0000\n",
      "Epoch 284/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 47621664.0000 - val_loss: 4622381.5000\n",
      "Epoch 285/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 48124696.0000 - val_loss: 27565518.0000\n",
      "Epoch 286/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 171246992.0000 - val_loss: 181677136.0000\n",
      "Epoch 287/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 852532608.0000 - val_loss: 734095872.0000\n",
      "Epoch 288/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 509031552.0000 - val_loss: 201982160.0000\n",
      "Epoch 289/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 271439840.0000 - val_loss: 110096224.0000\n",
      "Epoch 290/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 96748232.0000 - val_loss: 8747691.0000\n",
      "Epoch 291/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52516788.0000 - val_loss: 20703170.0000\n",
      "Epoch 292/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60634264.0000 - val_loss: 47966428.0000\n",
      "Epoch 293/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 108679288.0000 - val_loss: 4675722.0000\n",
      "Epoch 294/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 82081664.0000 - val_loss: 41657432.0000\n",
      "Epoch 295/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49516536.0000 - val_loss: 53713320.0000\n",
      "Epoch 296/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 93778328.0000 - val_loss: 130248360.0000\n",
      "Epoch 297/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 115774784.0000 - val_loss: 24132534.0000\n",
      "Epoch 298/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 130297560.0000 - val_loss: 55508004.0000\n",
      "Epoch 299/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72352192.0000 - val_loss: 82817024.0000\n",
      "Epoch 300/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 80659416.0000 - val_loss: 454668288.0000\n",
      "Epoch 301/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 241167504.0000 - val_loss: 34452496.0000\n",
      "Epoch 302/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143447952.0000 - val_loss: 2798011.0000\n",
      "Epoch 303/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144339040.0000 - val_loss: 113812176.0000\n",
      "Epoch 304/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 343013120.0000 - val_loss: 280327520.0000\n",
      "Epoch 305/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 223470320.0000 - val_loss: 81180336.0000\n",
      "Epoch 306/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 108207232.0000 - val_loss: 72822904.0000\n",
      "Epoch 307/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 297673888.0000 - val_loss: 2060344832.0000\n",
      "Epoch 308/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 807251904.0000 - val_loss: 1030045952.0000\n",
      "Epoch 309/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 382990912.0000 - val_loss: 82955232.0000\n",
      "Epoch 310/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 235195472.0000 - val_loss: 23224968.0000\n",
      "Epoch 311/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137932512.0000 - val_loss: 3657919.7500\n",
      "Epoch 312/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 240163984.0000 - val_loss: 26237100.0000\n",
      "Epoch 313/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65116308.0000 - val_loss: 213369808.0000\n",
      "Epoch 314/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 268107232.0000 - val_loss: 819188672.0000\n",
      "Epoch 315/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 441972352.0000 - val_loss: 56306920.0000\n",
      "Epoch 316/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 183866944.0000 - val_loss: 1968302.6250\n",
      "Epoch 317/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65784528.0000 - val_loss: 13410164.0000\n",
      "Epoch 318/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 88485176.0000 - val_loss: 3627898.7500\n",
      "Epoch 319/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 83866216.0000 - val_loss: 15641664.0000\n",
      "Epoch 320/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 71454696.0000 - val_loss: 102927536.0000\n",
      "Epoch 321/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 255506512.0000 - val_loss: 17554934.0000\n",
      "Epoch 322/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 45979860.0000 - val_loss: 211404320.0000\n",
      "Epoch 323/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145774144.0000 - val_loss: 16196018.0000\n",
      "Epoch 324/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 69186880.0000 - val_loss: 35103412.0000\n",
      "Epoch 325/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 83988624.0000 - val_loss: 47540440.0000\n",
      "Epoch 326/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 97279520.0000 - val_loss: 15025456.0000\n",
      "Epoch 327/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 290420512.0000 - val_loss: 1174065664.0000\n",
      "Epoch 328/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 608258752.0000 - val_loss: 154341488.0000\n",
      "Epoch 329/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71635120.0000 - val_loss: 6315386.0000\n",
      "Epoch 330/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129652672.0000 - val_loss: 8255935.0000\n",
      "Epoch 331/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61102776.0000 - val_loss: 2762061.0000\n",
      "Epoch 332/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26815228.0000 - val_loss: 35087432.0000\n",
      "Epoch 333/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 176194944.0000 - val_loss: 50194980.0000\n",
      "Epoch 334/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 42467608.0000 - val_loss: 7465916.5000\n",
      "Epoch 335/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 62899372.0000 - val_loss: 83379144.0000\n",
      "Epoch 336/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 40154220.0000 - val_loss: 2606689.5000\n",
      "Epoch 337/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18763258.0000 - val_loss: 11419538.0000\n",
      "Epoch 338/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52564144.0000 - val_loss: 1214227.1250\n",
      "Epoch 339/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 33366074.0000 - val_loss: 56477172.0000\n",
      "Epoch 340/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 95306816.0000 - val_loss: 136220640.0000\n",
      "Epoch 341/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 119018016.0000 - val_loss: 308996224.0000\n",
      "Epoch 342/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 289859936.0000 - val_loss: 62059100.0000\n",
      "Epoch 343/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 76731256.0000 - val_loss: 151325824.0000\n",
      "Epoch 344/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 162055488.0000 - val_loss: 45211084.0000\n",
      "Epoch 345/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 83712912.0000 - val_loss: 43894232.0000\n",
      "Epoch 346/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145250608.0000 - val_loss: 44865600.0000\n",
      "Epoch 347/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 317107168.0000 - val_loss: 176134576.0000\n",
      "Epoch 348/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 332101696.0000 - val_loss: 75051536.0000\n",
      "Epoch 349/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 94669720.0000 - val_loss: 79432000.0000\n",
      "Epoch 350/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 79644552.0000 - val_loss: 38566880.0000\n",
      "Epoch 351/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 76163016.0000 - val_loss: 4559267.5000\n",
      "Epoch 352/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 99020000.0000 - val_loss: 71088520.0000\n",
      "Epoch 353/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 144608832.0000 - val_loss: 590848256.0000\n",
      "Epoch 354/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 366985888.0000 - val_loss: 432674912.0000\n",
      "Epoch 355/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 469873792.0000 - val_loss: 219953984.0000\n",
      "Epoch 356/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192636064.0000 - val_loss: 170124624.0000\n",
      "Epoch 357/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148491072.0000 - val_loss: 7768267.5000\n",
      "Epoch 358/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 64707112.0000 - val_loss: 10010541.0000\n",
      "Epoch 359/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 46707764.0000 - val_loss: 2314260.0000\n",
      "Epoch 360/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 36751392.0000 - val_loss: 21843098.0000\n",
      "Epoch 361/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 35679832.0000 - val_loss: 3005165.2500\n",
      "Epoch 362/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15473114.0000 - val_loss: 21058046.0000\n",
      "Epoch 363/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 31874632.0000 - val_loss: 19764222.0000\n",
      "Epoch 364/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52215276.0000 - val_loss: 11577504.0000\n",
      "Epoch 365/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50657104.0000 - val_loss: 3062098.0000\n",
      "Epoch 366/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 47770504.0000 - val_loss: 24293282.0000\n",
      "Epoch 367/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37978688.0000 - val_loss: 1282378.6250\n",
      "Epoch 368/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21470028.0000 - val_loss: 15008103.0000\n",
      "Epoch 369/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31141150.0000 - val_loss: 57261360.0000\n",
      "Epoch 370/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 44017468.0000 - val_loss: 44827572.0000\n",
      "Epoch 371/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141381040.0000 - val_loss: 759996928.0000\n",
      "Epoch 372/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 406901600.0000 - val_loss: 168936000.0000\n",
      "Epoch 373/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 106501712.0000 - val_loss: 4550794.0000\n",
      "Epoch 374/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27038368.0000 - val_loss: 70219344.0000\n",
      "Epoch 375/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57920368.0000 - val_loss: 5133696.0000\n",
      "Epoch 376/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25968202.0000 - val_loss: 9513881.0000\n",
      "Epoch 377/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 90576368.0000 - val_loss: 152158176.0000\n",
      "Epoch 378/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91393944.0000 - val_loss: 5746800.0000\n",
      "Epoch 379/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14710560.0000 - val_loss: 7288128.0000\n",
      "Epoch 380/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13683795.0000 - val_loss: 1062430.6250\n",
      "Epoch 381/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11815082.0000 - val_loss: 10595842.0000\n",
      "Epoch 382/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37559724.0000 - val_loss: 12339228.0000\n",
      "Epoch 383/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 94940496.0000 - val_loss: 142090448.0000\n",
      "Epoch 384/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64592348.0000 - val_loss: 9362866.0000\n",
      "Epoch 385/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 39657372.0000 - val_loss: 1164494.2500\n",
      "Epoch 386/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20893290.0000 - val_loss: 141557472.0000\n",
      "Epoch 387/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 81056720.0000 - val_loss: 6498506.0000\n",
      "Epoch 388/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17386780.0000 - val_loss: 3656087.0000\n",
      "Epoch 389/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 42570676.0000 - val_loss: 78635584.0000\n",
      "Epoch 390/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 136454480.0000 - val_loss: 5710854.0000\n",
      "Epoch 391/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 37517492.0000 - val_loss: 201072992.0000\n",
      "Epoch 392/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 236482960.0000 - val_loss: 274737632.0000\n",
      "Epoch 393/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 151759024.0000 - val_loss: 134260032.0000\n",
      "Epoch 394/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 163955312.0000 - val_loss: 193737264.0000\n",
      "Epoch 395/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 285532096.0000 - val_loss: 85880352.0000\n",
      "Epoch 396/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 177660992.0000 - val_loss: 325870208.0000\n",
      "Epoch 397/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115247352.0000 - val_loss: 2105634.5000\n",
      "Epoch 398/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26947990.0000 - val_loss: 52595100.0000\n",
      "Epoch 399/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 47385208.0000 - val_loss: 10662926.0000\n",
      "Epoch 400/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28359928.0000 - val_loss: 4465730.0000\n",
      "Epoch 401/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 74659896.0000 - val_loss: 24434828.0000\n",
      "Epoch 402/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 57977520.0000 - val_loss: 55978648.0000\n",
      "Epoch 403/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 36860004.0000 - val_loss: 430457.2500\n",
      "Epoch 404/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13480072.0000 - val_loss: 913115.5625\n",
      "Epoch 405/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26882140.0000 - val_loss: 67367256.0000\n",
      "Epoch 406/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54089332.0000 - val_loss: 1647834.5000\n",
      "Epoch 407/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32360616.0000 - val_loss: 18304280.0000\n",
      "Epoch 408/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56060856.0000 - val_loss: 419520960.0000\n",
      "Epoch 409/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 182426512.0000 - val_loss: 15731294.0000\n",
      "Epoch 410/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23556930.0000 - val_loss: 3239101.7500\n",
      "Epoch 411/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14790372.0000 - val_loss: 12329809.0000\n",
      "Epoch 412/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 164291584.0000 - val_loss: 343708448.0000\n",
      "Epoch 413/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 271732704.0000 - val_loss: 11269661.0000\n",
      "Epoch 414/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68692720.0000 - val_loss: 114669816.0000\n",
      "Epoch 415/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67084796.0000 - val_loss: 4113341.0000\n",
      "Epoch 416/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17736012.0000 - val_loss: 8779116.0000\n",
      "Epoch 417/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 37049212.0000 - val_loss: 778026.3125\n",
      "Epoch 418/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 39464704.0000 - val_loss: 12819105.0000\n",
      "Epoch 419/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32150510.0000 - val_loss: 22309000.0000\n",
      "Epoch 420/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23804610.0000 - val_loss: 38367828.0000\n",
      "Epoch 421/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 73556008.0000 - val_loss: 96853400.0000\n",
      "Epoch 422/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151082272.0000 - val_loss: 152504512.0000\n",
      "Epoch 423/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124366152.0000 - val_loss: 4382821.0000\n",
      "Epoch 424/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 35849468.0000 - val_loss: 41659060.0000\n",
      "Epoch 425/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29152002.0000 - val_loss: 30233688.0000\n",
      "Epoch 426/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28094048.0000 - val_loss: 18802402.0000\n",
      "Epoch 427/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34129340.0000 - val_loss: 28398120.0000\n",
      "Epoch 428/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 45416196.0000 - val_loss: 4942336.0000\n",
      "Epoch 429/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33567080.0000 - val_loss: 1559454.2500\n",
      "Epoch 430/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11606720.0000 - val_loss: 1393141.7500\n",
      "Epoch 431/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28558268.0000 - val_loss: 7491673.0000\n",
      "Epoch 432/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10174108.0000 - val_loss: 1532624.8750\n",
      "Epoch 433/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5517088.0000 - val_loss: 7034495.0000\n",
      "Epoch 434/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15278669.0000 - val_loss: 3841801.2500\n",
      "Epoch 435/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 45316816.0000 - val_loss: 255966320.0000\n",
      "Epoch 436/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 117159856.0000 - val_loss: 1511588.8750\n",
      "Epoch 437/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 43492740.0000 - val_loss: 9589130.0000\n",
      "Epoch 438/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 76913928.0000 - val_loss: 3522221.2500\n",
      "Epoch 439/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57368224.0000 - val_loss: 3976657.2500\n",
      "Epoch 440/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58600296.0000 - val_loss: 56003860.0000\n",
      "Epoch 441/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 336419264.0000 - val_loss: 829821568.0000\n",
      "Epoch 442/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 281099968.0000 - val_loss: 29343784.0000\n",
      "Epoch 443/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 94730248.0000 - val_loss: 9055508.0000\n",
      "Epoch 444/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67255864.0000 - val_loss: 218244928.0000\n",
      "Epoch 445/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192758336.0000 - val_loss: 166166544.0000\n",
      "Epoch 446/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 93333896.0000 - val_loss: 861567.7500\n",
      "Epoch 447/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16174300.0000 - val_loss: 1619119.7500\n",
      "Epoch 448/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 31080214.0000 - val_loss: 181753200.0000\n",
      "Epoch 449/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 80320048.0000 - val_loss: 16144373.0000\n",
      "Epoch 450/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18120046.0000 - val_loss: 13893665.0000\n",
      "Epoch 451/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24325470.0000 - val_loss: 62347920.0000\n",
      "Epoch 452/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113328488.0000 - val_loss: 307027584.0000\n",
      "Epoch 453/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 180261984.0000 - val_loss: 66954412.0000\n",
      "Epoch 454/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 39738096.0000 - val_loss: 1488613.7500\n",
      "Epoch 455/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 43343472.0000 - val_loss: 5367644.5000\n",
      "Epoch 456/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9489500.0000 - val_loss: 26055542.0000\n",
      "Epoch 457/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30608662.0000 - val_loss: 1155057.1250\n",
      "Epoch 458/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19477854.0000 - val_loss: 303531.5000\n",
      "Epoch 459/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7313874.5000 - val_loss: 6217536.0000\n",
      "Epoch 460/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13158227.0000 - val_loss: 15458859.0000\n",
      "Epoch 461/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20653684.0000 - val_loss: 4661508.5000\n",
      "Epoch 462/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59975700.0000 - val_loss: 1311794.8750\n",
      "Epoch 463/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30793766.0000 - val_loss: 7993161.0000\n",
      "Epoch 464/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10591951.0000 - val_loss: 19153800.0000\n",
      "Epoch 465/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20480464.0000 - val_loss: 11138738.0000\n",
      "Epoch 466/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 40107360.0000 - val_loss: 44271436.0000\n",
      "Epoch 467/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 153315968.0000 - val_loss: 92841336.0000\n",
      "Epoch 468/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121852096.0000 - val_loss: 5575862.0000\n",
      "Epoch 469/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19416920.0000 - val_loss: 10658301.0000\n",
      "Epoch 470/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15333080.0000 - val_loss: 99194272.0000\n",
      "Epoch 471/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60198756.0000 - val_loss: 5437291.0000\n",
      "Epoch 472/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63676876.0000 - val_loss: 62008660.0000\n",
      "Epoch 473/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49205576.0000 - val_loss: 32048462.0000\n",
      "Epoch 474/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17834982.0000 - val_loss: 395340.2188\n",
      "Epoch 475/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 34615612.0000 - val_loss: 171637824.0000\n",
      "Epoch 476/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137250864.0000 - val_loss: 22089128.0000\n",
      "Epoch 477/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63382628.0000 - val_loss: 1542153.2500\n",
      "Epoch 478/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 33660020.0000 - val_loss: 7731472.0000\n",
      "Epoch 479/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17511526.0000 - val_loss: 18655192.0000\n",
      "Epoch 480/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15048298.0000 - val_loss: 16104581.0000\n",
      "Epoch 481/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21253066.0000 - val_loss: 53798216.0000\n",
      "Epoch 482/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 45784128.0000 - val_loss: 2316615.7500\n",
      "Epoch 483/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10907820.0000 - val_loss: 14197534.0000\n",
      "Epoch 484/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23001770.0000 - val_loss: 11358532.0000\n",
      "Epoch 485/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34812748.0000 - val_loss: 4845434.5000\n",
      "Epoch 486/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9969499.0000 - val_loss: 15780263.0000\n",
      "Epoch 487/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24641594.0000 - val_loss: 2537440.5000\n",
      "Epoch 488/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23644098.0000 - val_loss: 10494581.0000\n",
      "Epoch 489/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27409624.0000 - val_loss: 30627786.0000\n",
      "Epoch 490/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16557759.0000 - val_loss: 11000432.0000\n",
      "Epoch 491/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17104778.0000 - val_loss: 3379465.0000\n",
      "Epoch 492/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5717248.0000 - val_loss: 2078617.7500\n",
      "Epoch 493/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5545510.5000 - val_loss: 115887.4453\n",
      "Epoch 494/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9928781.0000 - val_loss: 823098.7500\n",
      "Epoch 495/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20021254.0000 - val_loss: 341690.1562\n",
      "Epoch 496/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72714328.0000 - val_loss: 176532992.0000\n",
      "Epoch 497/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 165919472.0000 - val_loss: 124168832.0000\n",
      "Epoch 498/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 193267856.0000 - val_loss: 36541160.0000\n",
      "Epoch 499/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24803074.0000 - val_loss: 6734132.0000\n",
      "Epoch 500/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23144792.0000 - val_loss: 9714789.0000\n",
      "Epoch 501/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 34744056.0000 - val_loss: 2965623.2500\n",
      "Epoch 502/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22865312.0000 - val_loss: 9952313.0000\n",
      "Epoch 503/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6599802.5000 - val_loss: 480485.4375\n",
      "Epoch 504/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2918944.0000 - val_loss: 1662312.8750\n",
      "Epoch 505/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11013180.0000 - val_loss: 11537991.0000\n",
      "Epoch 506/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14251208.0000 - val_loss: 15611975.0000\n",
      "Epoch 507/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28651326.0000 - val_loss: 110222440.0000\n",
      "Epoch 508/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 34109584.0000 - val_loss: 2150337.0000\n",
      "Epoch 509/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24117876.0000 - val_loss: 91656800.0000\n",
      "Epoch 510/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 63228364.0000 - val_loss: 41614508.0000\n",
      "Epoch 511/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25423488.0000 - val_loss: 9536102.0000\n",
      "Epoch 512/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12608938.0000 - val_loss: 3719317.2500\n",
      "Epoch 513/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16224572.0000 - val_loss: 10227212.0000\n",
      "Epoch 514/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9177048.0000 - val_loss: 19275982.0000\n",
      "Epoch 515/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 42914476.0000 - val_loss: 67043128.0000\n",
      "Epoch 516/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 40846008.0000 - val_loss: 19362204.0000\n",
      "Epoch 517/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 14135484.0000 - val_loss: 6682758.0000\n",
      "Epoch 518/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29950684.0000 - val_loss: 105427904.0000\n",
      "Epoch 519/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 81123704.0000 - val_loss: 33258552.0000\n",
      "Epoch 520/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26350688.0000 - val_loss: 23503472.0000\n",
      "Epoch 521/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 29375568.0000 - val_loss: 873810.3125\n",
      "Epoch 522/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 11323911.0000 - val_loss: 3878105.7500\n",
      "Epoch 523/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9118409.0000 - val_loss: 1791868.6250\n",
      "Epoch 524/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3188512.2500 - val_loss: 11376636.0000\n",
      "Epoch 525/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18745508.0000 - val_loss: 14939182.0000\n",
      "Epoch 526/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24625284.0000 - val_loss: 102032952.0000\n",
      "Epoch 527/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 89176704.0000 - val_loss: 1218945.0000\n",
      "Epoch 528/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14896909.0000 - val_loss: 21959840.0000\n",
      "Epoch 529/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18697130.0000 - val_loss: 17707542.0000\n",
      "Epoch 530/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 33917384.0000 - val_loss: 7758104.0000\n",
      "Epoch 531/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 951ms/step - loss: 8243589.5000 - val_loss: 57071008.0000\n",
      "Epoch 532/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 74455136.0000 - val_loss: 3139941.7500\n",
      "Epoch 533/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 204922304.0000 - val_loss: 20988056.0000\n",
      "Epoch 534/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 120090944.0000 - val_loss: 51218356.0000\n",
      "Epoch 535/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64505608.0000 - val_loss: 69138312.0000\n",
      "Epoch 536/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115242200.0000 - val_loss: 49209932.0000\n",
      "Epoch 537/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60950368.0000 - val_loss: 4678141.0000\n",
      "Epoch 538/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20543890.0000 - val_loss: 3381346.0000\n",
      "Epoch 539/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11383075.0000 - val_loss: 802575.7500\n",
      "Epoch 540/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14499657.0000 - val_loss: 1411612.7500\n",
      "Epoch 541/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7317728.5000 - val_loss: 1074305.5000\n",
      "Epoch 542/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12492905.0000 - val_loss: 1123050.7500\n",
      "Epoch 543/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10690710.0000 - val_loss: 2410336.7500\n",
      "Epoch 544/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6799157.5000 - val_loss: 966524.0000\n",
      "Epoch 545/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5843917.0000 - val_loss: 33586324.0000\n",
      "Epoch 546/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 39849352.0000 - val_loss: 45914288.0000\n",
      "Epoch 547/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53958604.0000 - val_loss: 2152541.5000\n",
      "Epoch 548/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4399907.5000 - val_loss: 2996127.7500\n",
      "Epoch 549/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6192564.5000 - val_loss: 1387491.5000\n",
      "Epoch 550/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10287503.0000 - val_loss: 88761296.0000\n",
      "Epoch 551/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 37412636.0000 - val_loss: 35714492.0000\n",
      "Epoch 552/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56648096.0000 - val_loss: 55576420.0000\n",
      "Epoch 553/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 50483980.0000 - val_loss: 1342320.7500\n",
      "Epoch 554/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8323864.5000 - val_loss: 733078.7500\n",
      "Epoch 555/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5599710.5000 - val_loss: 464440.2812\n",
      "Epoch 556/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6349795.5000 - val_loss: 32087214.0000\n",
      "Epoch 557/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15447601.0000 - val_loss: 3076337.7500\n",
      "Epoch 558/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10168513.0000 - val_loss: 1461973.1250\n",
      "Epoch 559/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10449116.0000 - val_loss: 118209.5703\n",
      "Epoch 560/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3071231.7500 - val_loss: 5640839.0000\n",
      "Epoch 561/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5033096.5000 - val_loss: 290945.5000\n",
      "Epoch 562/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4208885.5000 - val_loss: 114725.7734\n",
      "Epoch 563/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9974899.0000 - val_loss: 8909859.0000\n",
      "Epoch 564/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13307200.0000 - val_loss: 9304484.0000\n",
      "Epoch 565/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9474121.0000 - val_loss: 314028.0000\n",
      "Epoch 566/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5240361.0000 - val_loss: 515019.2188\n",
      "Epoch 567/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4424299.0000 - val_loss: 3049889.2500\n",
      "Epoch 568/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 13901604.0000 - val_loss: 135480.6719\n",
      "Epoch 569/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15107167.0000 - val_loss: 10463172.0000\n",
      "Epoch 570/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6710240.5000 - val_loss: 11715454.0000\n",
      "Epoch 571/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7887122.5000 - val_loss: 2280209.5000\n",
      "Epoch 572/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5409307.5000 - val_loss: 464409.0000\n",
      "Epoch 573/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5552334.5000 - val_loss: 3109619.0000\n",
      "Epoch 574/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2239643.0000 - val_loss: 2347827.2500\n",
      "Epoch 575/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22265428.0000 - val_loss: 43305812.0000\n",
      "Epoch 576/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 58568560.0000 - val_loss: 18916898.0000\n",
      "Epoch 577/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14926038.0000 - val_loss: 3139256.7500\n",
      "Epoch 578/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18431492.0000 - val_loss: 14649175.0000\n",
      "Epoch 579/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16873782.0000 - val_loss: 53247964.0000\n",
      "Epoch 580/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 44524712.0000 - val_loss: 99231376.0000\n",
      "Epoch 581/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 33827516.0000 - val_loss: 2747931.7500\n",
      "Epoch 582/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5584014.5000 - val_loss: 3735754.2500\n",
      "Epoch 583/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5464816.5000 - val_loss: 1997853.1250\n",
      "Epoch 584/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5569519.0000 - val_loss: 11426129.0000\n",
      "Epoch 585/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9598387.0000 - val_loss: 7352248.0000\n",
      "Epoch 586/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6978337.5000 - val_loss: 3049583.2500\n",
      "Epoch 587/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7456857.5000 - val_loss: 2090687.3750\n",
      "Epoch 588/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2771591.5000 - val_loss: 2349791.2500\n",
      "Epoch 589/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7340530.5000 - val_loss: 358292.0938\n",
      "Epoch 590/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1693501.0000 - val_loss: 2107436.2500\n",
      "Epoch 591/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1848947.5000 - val_loss: 1134347.7500\n",
      "Epoch 592/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2345465.5000 - val_loss: 571744.3750\n",
      "Epoch 593/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7809780.0000 - val_loss: 14626929.0000\n",
      "Epoch 594/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7782782.0000 - val_loss: 5721662.5000\n",
      "Epoch 595/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2729352.7500 - val_loss: 7047374.5000\n",
      "Epoch 596/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25737318.0000 - val_loss: 7382835.5000\n",
      "Epoch 597/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26935198.0000 - val_loss: 54108324.0000\n",
      "Epoch 598/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 40851992.0000 - val_loss: 2372927.0000\n",
      "Epoch 599/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30704494.0000 - val_loss: 24564858.0000\n",
      "Epoch 600/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24506678.0000 - val_loss: 6348568.0000\n",
      "Epoch 601/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12421299.0000 - val_loss: 523436.1250\n",
      "Epoch 602/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 13318956.0000 - val_loss: 10124808.0000\n",
      "Epoch 603/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8737821.0000 - val_loss: 12417550.0000\n",
      "Epoch 604/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63295336.0000 - val_loss: 49484896.0000\n",
      "Epoch 605/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 58049604.0000 - val_loss: 1522528.3750\n",
      "Epoch 606/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23631370.0000 - val_loss: 29271776.0000\n",
      "Epoch 607/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27302370.0000 - val_loss: 9869844.0000\n",
      "Epoch 608/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8523732.0000 - val_loss: 1642577.5000\n",
      "Epoch 609/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4407434.0000 - val_loss: 422243.5625\n",
      "Epoch 610/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8223381.0000 - val_loss: 3967231.0000\n",
      "Epoch 611/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8730856.0000 - val_loss: 209314.4688\n",
      "Epoch 612/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1722949.0000 - val_loss: 2451928.7500\n",
      "Epoch 613/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2422654.2500 - val_loss: 51200.1992\n",
      "Epoch 614/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4948701.0000 - val_loss: 3338471.2500\n",
      "Epoch 615/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13225243.0000 - val_loss: 4653721.0000\n",
      "Epoch 616/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2735062.0000 - val_loss: 1478891.7500\n",
      "Epoch 617/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3142419.2500 - val_loss: 271147.3125\n",
      "Epoch 618/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6974081.0000 - val_loss: 7906725.5000\n",
      "Epoch 619/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4934947.5000 - val_loss: 1252286.1250\n",
      "Epoch 620/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16611859.0000 - val_loss: 11411733.0000\n",
      "Epoch 621/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18355014.0000 - val_loss: 671312.0000\n",
      "Epoch 622/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21440446.0000 - val_loss: 24652246.0000\n",
      "Epoch 623/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12336312.0000 - val_loss: 4477776.0000\n",
      "Epoch 624/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7492332.0000 - val_loss: 30333326.0000\n",
      "Epoch 625/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11530995.0000 - val_loss: 178195.1250\n",
      "Epoch 626/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1018839.8750 - val_loss: 632106.0000\n",
      "Epoch 627/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1421732.1250 - val_loss: 1612454.5000\n",
      "Epoch 628/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1545357.5000 - val_loss: 1274143.6250\n",
      "Epoch 629/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1062045.2500 - val_loss: 225350.6875\n",
      "Epoch 630/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2663455.7500 - val_loss: 1074089.1250\n",
      "Epoch 631/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2635829.7500 - val_loss: 375941.7500\n",
      "Epoch 632/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7150797.5000 - val_loss: 1067563.1250\n",
      "Epoch 633/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1106838.6250 - val_loss: 72262.5234\n",
      "Epoch 634/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 504230.5625 - val_loss: 61507.7305\n",
      "Epoch 635/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28150408.0000 - val_loss: 58100452.0000\n",
      "Epoch 636/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 94249664.0000 - val_loss: 3149016.0000\n",
      "Epoch 637/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7238302.0000 - val_loss: 11191488.0000\n",
      "Epoch 638/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13845174.0000 - val_loss: 3749370.7500\n",
      "Epoch 639/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4550427.0000 - val_loss: 2851133.7500\n",
      "Epoch 640/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2375467.0000 - val_loss: 1684518.0000\n",
      "Epoch 641/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4763354.0000 - val_loss: 2251462.0000\n",
      "Epoch 642/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2191239.5000 - val_loss: 2989009.5000\n",
      "Epoch 643/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14183195.0000 - val_loss: 11203620.0000\n",
      "Epoch 644/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11278729.0000 - val_loss: 27406022.0000\n",
      "Epoch 645/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28162962.0000 - val_loss: 29600318.0000\n",
      "Epoch 646/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17153606.0000 - val_loss: 159587.7188\n",
      "Epoch 647/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2651087.5000 - val_loss: 575575.2500\n",
      "Epoch 648/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12768028.0000 - val_loss: 6682754.0000\n",
      "Epoch 649/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6244258.5000 - val_loss: 10554812.0000\n",
      "Epoch 650/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8474649.0000 - val_loss: 6785871.0000\n",
      "Epoch 651/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3278026.2500 - val_loss: 519287.0625\n",
      "Epoch 652/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2313294.2500 - val_loss: 1229980.1250\n",
      "Epoch 653/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15859539.0000 - val_loss: 119876112.0000\n",
      "Epoch 654/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 46176764.0000 - val_loss: 13593322.0000\n",
      "Epoch 655/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9618715.0000 - val_loss: 3400545.0000\n",
      "Epoch 656/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3871537.7500 - val_loss: 329114.6250\n",
      "Epoch 657/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2199714.2500 - val_loss: 251725.9219\n",
      "Epoch 658/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3611421.2500 - val_loss: 2221428.7500\n",
      "Epoch 659/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3527809.5000 - val_loss: 2449289.7500\n",
      "Epoch 660/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4038100.2500 - val_loss: 891205.4375\n",
      "Epoch 661/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1972002.3750 - val_loss: 181679.2969\n",
      "Epoch 662/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1059930.0000 - val_loss: 1445923.1250\n",
      "Epoch 663/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3161349.0000 - val_loss: 1152099.8750\n",
      "Epoch 664/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3063358.7500 - val_loss: 1739874.3750\n",
      "Epoch 665/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1247607.6250 - val_loss: 1211981.7500\n",
      "Epoch 666/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1345412.7500 - val_loss: 100901.7891\n",
      "Epoch 667/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 18382096.0000 - val_loss: 23095948.0000\n",
      "Epoch 668/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25415326.0000 - val_loss: 1148640.7500\n",
      "Epoch 669/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26524430.0000 - val_loss: 1585761.3750\n",
      "Epoch 670/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 18867030.0000 - val_loss: 3232623.0000\n",
      "Epoch 671/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6634153.0000 - val_loss: 20937266.0000\n",
      "Epoch 672/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14511941.0000 - val_loss: 6253682.5000\n",
      "Epoch 673/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11564165.0000 - val_loss: 3661152.7500\n",
      "Epoch 674/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4719805.0000 - val_loss: 145596.4375\n",
      "Epoch 675/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3486603.5000 - val_loss: 222449.6562\n",
      "Epoch 676/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1139391.6250 - val_loss: 8076346.0000\n",
      "Epoch 677/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8862887.0000 - val_loss: 4827258.5000\n",
      "Epoch 678/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5346826.0000 - val_loss: 530692.4375\n",
      "Epoch 679/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2736807.0000 - val_loss: 5474999.5000\n",
      "Epoch 680/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3704497.5000 - val_loss: 203951.2344\n",
      "Epoch 681/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1748153.0000 - val_loss: 792808.1875\n",
      "Epoch 682/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 962814.8750 - val_loss: 40315.0859\n",
      "Epoch 683/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1031720.6875 - val_loss: 1067595.8750\n",
      "Epoch 684/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2820677.2500 - val_loss: 174989.6406\n",
      "Epoch 685/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 990798.7500 - val_loss: 644605.8125\n",
      "Epoch 686/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1269939.2500 - val_loss: 1072314.5000\n",
      "Epoch 687/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2128876.0000 - val_loss: 938119.8750\n",
      "Epoch 688/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3782150.2500 - val_loss: 1272143.8750\n",
      "Epoch 689/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3473514.2500 - val_loss: 14473978.0000\n",
      "Epoch 690/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9589242.0000 - val_loss: 8511480.0000\n",
      "Epoch 691/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5764203.0000 - val_loss: 94762.0703\n",
      "Epoch 692/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 947777.7500 - val_loss: 241683.3594\n",
      "Epoch 693/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1124940.3750 - val_loss: 27270.3340\n",
      "Epoch 694/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 526860.5625 - val_loss: 244675.6094\n",
      "Epoch 695/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1039217.1250 - val_loss: 2349650.2500\n",
      "Epoch 696/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2552900.0000 - val_loss: 903736.0000\n",
      "Epoch 697/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 762371.5000 - val_loss: 134356.9375\n",
      "Epoch 698/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1227133.2500 - val_loss: 883079.0000\n",
      "Epoch 699/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 922725.2500 - val_loss: 7324997.0000\n",
      "Epoch 700/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9027775.0000 - val_loss: 7194074.0000\n",
      "Epoch 701/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4244651.0000 - val_loss: 1341782.5000\n",
      "Epoch 702/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4299103.5000 - val_loss: 3140632.2500\n",
      "Epoch 703/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5303162.5000 - val_loss: 1635891.7500\n",
      "Epoch 704/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1828204.2500 - val_loss: 2117057.0000\n",
      "Epoch 705/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3420820.0000 - val_loss: 1882844.6250\n",
      "Epoch 706/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3818042.0000 - val_loss: 2215418.2500\n",
      "Epoch 707/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6570963.0000 - val_loss: 490494.3750\n",
      "Epoch 708/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 796188.7500 - val_loss: 1534320.5000\n",
      "Epoch 709/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1995781.7500 - val_loss: 474350.0625\n",
      "Epoch 710/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1030768.8750 - val_loss: 6409621.5000\n",
      "Epoch 711/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3625876.0000 - val_loss: 77529.5078\n",
      "Epoch 712/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2438918.2500 - val_loss: 252820.5625\n",
      "Epoch 713/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1628250.6250 - val_loss: 1332132.8750\n",
      "Epoch 714/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1387265.3750 - val_loss: 245993.1719\n",
      "Epoch 715/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2446892.5000 - val_loss: 3343812.0000\n",
      "Epoch 716/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3493833.2500 - val_loss: 12527803.0000\n",
      "Epoch 717/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4768569.0000 - val_loss: 178502.7812\n",
      "Epoch 718/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3552279.7500 - val_loss: 234248.1094\n",
      "Epoch 719/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1333146.8750 - val_loss: 461789.6875\n",
      "Epoch 720/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4587615.5000 - val_loss: 1506773.8750\n",
      "Epoch 721/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3090311.7500 - val_loss: 5368743.0000\n",
      "Epoch 722/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3371976.0000 - val_loss: 197333.2500\n",
      "Epoch 723/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2779390.7500 - val_loss: 1728832.5000\n",
      "Epoch 724/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4433776.0000 - val_loss: 579540.2500\n",
      "Epoch 725/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1669645.0000 - val_loss: 148287.1875\n",
      "Epoch 726/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1057577.0000 - val_loss: 400747.5000\n",
      "Epoch 727/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1323352.5000 - val_loss: 917230.6875\n",
      "Epoch 728/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4311120.0000 - val_loss: 1937972.2500\n",
      "Epoch 729/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2378779.0000 - val_loss: 633006.2500\n",
      "Epoch 730/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4322855.0000 - val_loss: 5314610.5000\n",
      "Epoch 731/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3950501.2500 - val_loss: 1770730.1250\n",
      "Epoch 732/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5158323.5000 - val_loss: 1451127.8750\n",
      "Epoch 733/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2968601.5000 - val_loss: 202808.2500\n",
      "Epoch 734/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1769619.1250 - val_loss: 5741192.0000\n",
      "Epoch 735/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24526258.0000 - val_loss: 2899280.2500\n",
      "Epoch 736/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2594237.7500 - val_loss: 277724.4688\n",
      "Epoch 737/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3975831.7500 - val_loss: 425858.3125\n",
      "Epoch 738/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2009801.1250 - val_loss: 177811.7344\n",
      "Epoch 739/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2648618.5000 - val_loss: 1174886.3750\n",
      "Epoch 740/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4289547.0000 - val_loss: 1759114.0000\n",
      "Epoch 741/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3457495.0000 - val_loss: 3805908.0000\n",
      "Epoch 742/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6963885.5000 - val_loss: 2194067.0000\n",
      "Epoch 743/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7504871.5000 - val_loss: 3411715.0000\n",
      "Epoch 744/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3490282.0000 - val_loss: 1484633.8750\n",
      "Epoch 745/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5741270.5000 - val_loss: 36878896.0000\n",
      "Epoch 746/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19844602.0000 - val_loss: 4462323.5000\n",
      "Epoch 747/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4969708.5000 - val_loss: 2429242.0000\n",
      "Epoch 748/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4595647.5000 - val_loss: 1485985.5000\n",
      "Epoch 749/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2124427.2500 - val_loss: 544723.3125\n",
      "Epoch 750/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1802225.1250 - val_loss: 69861.8906\n",
      "Epoch 751/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1933852.7500 - val_loss: 2674196.5000\n",
      "Epoch 752/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1842144.1250 - val_loss: 845473.9375\n",
      "Epoch 753/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2647063.2500 - val_loss: 1652178.5000\n",
      "Epoch 754/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1200408.3750 - val_loss: 120176.6562\n",
      "Epoch 755/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1253995.7500 - val_loss: 500683.7188\n",
      "Epoch 756/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1910291.2500 - val_loss: 68674.8359\n",
      "Epoch 757/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 492557.8438 - val_loss: 2211894.2500\n",
      "Epoch 758/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4046823.0000 - val_loss: 10880412.0000\n",
      "Epoch 759/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9513276.0000 - val_loss: 652161.5000\n",
      "Epoch 760/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5821395.0000 - val_loss: 14452585.0000\n",
      "Epoch 761/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12836411.0000 - val_loss: 1763747.6250\n",
      "Epoch 762/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2319431.0000 - val_loss: 207496.2812\n",
      "Epoch 763/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1010560.8750 - val_loss: 191419.0938\n",
      "Epoch 764/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 731347.3750 - val_loss: 92208.1484\n",
      "Epoch 765/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3178598.5000 - val_loss: 266769.0625\n",
      "Epoch 766/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2431438.0000 - val_loss: 660872.7500\n",
      "Epoch 767/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1031741.1250 - val_loss: 52703.1719\n",
      "Epoch 768/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 565778.9375 - val_loss: 2317041.0000\n",
      "Epoch 769/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1247691.5000 - val_loss: 74579.5703\n",
      "Epoch 770/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 253018.5156 - val_loss: 47853.8242\n",
      "Epoch 771/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 257441.1875 - val_loss: 99306.2734\n",
      "Epoch 772/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 593974.1875 - val_loss: 49818.1445\n",
      "Epoch 773/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 306359.5938 - val_loss: 398974.4375\n",
      "Epoch 774/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 644449.5000 - val_loss: 423342.6250\n",
      "Epoch 775/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 492332.1562 - val_loss: 37081.7539\n",
      "Epoch 776/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 543798.0000 - val_loss: 333612.3750\n",
      "Epoch 777/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2976824.0000 - val_loss: 30833316.0000\n",
      "Epoch 778/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23801092.0000 - val_loss: 1601253.7500\n",
      "Epoch 779/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5841180.5000 - val_loss: 7458858.0000\n",
      "Epoch 780/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4928007.5000 - val_loss: 1282565.2500\n",
      "Epoch 781/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1645641.5000 - val_loss: 398706.7500\n",
      "Epoch 782/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3755496.0000 - val_loss: 3454561.7500\n",
      "Epoch 783/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2354025.2500 - val_loss: 5205330.5000\n",
      "Epoch 784/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8366618.5000 - val_loss: 2347830.0000\n",
      "Epoch 785/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2432790.2500 - val_loss: 551936.1250\n",
      "Epoch 786/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 664246.1250 - val_loss: 171929.5625\n",
      "Epoch 787/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29875518.0000 - val_loss: 64714824.0000\n",
      "Epoch 788/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1467532544.0000 - val_loss: 134239520.0000\n",
      "Epoch 789/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 392949056.0000 - val_loss: 16588967.0000\n",
      "Epoch 790/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134276032.0000 - val_loss: 6882637.5000\n",
      "Epoch 791/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22659282.0000 - val_loss: 2875832.7500\n",
      "Epoch 792/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18234806.0000 - val_loss: 1782628.2500\n",
      "Epoch 793/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10392780.0000 - val_loss: 1875861.7500\n",
      "Epoch 794/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10447935.0000 - val_loss: 927098.0000\n",
      "Epoch 795/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9898209.0000 - val_loss: 935738.1250\n",
      "Epoch 796/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5396567.5000 - val_loss: 527504.6250\n",
      "Epoch 797/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3690160.2500 - val_loss: 668698.5625\n",
      "Epoch 798/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4295203.0000 - val_loss: 1875531.1250\n",
      "Epoch 799/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9963641.0000 - val_loss: 3700477.2500\n",
      "Epoch 800/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7498099.0000 - val_loss: 9044628.0000\n",
      "Epoch 801/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6141463.0000 - val_loss: 542667.8750\n",
      "Epoch 802/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2186438.5000 - val_loss: 544160.7500\n",
      "Epoch 803/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2643837.5000 - val_loss: 687235.5000\n",
      "Epoch 804/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2370174.5000 - val_loss: 1612936.7500\n",
      "Epoch 805/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2302233.7500 - val_loss: 308515.7188\n",
      "Epoch 806/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1477913.3750 - val_loss: 1104287.5000\n",
      "Epoch 807/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3152082.5000 - val_loss: 918606.6875\n",
      "Epoch 808/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3656400.5000 - val_loss: 2951933.5000\n",
      "Epoch 809/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3116332.7500 - val_loss: 1106300.5000\n",
      "Epoch 810/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1643653.2500 - val_loss: 266361.1562\n",
      "Epoch 811/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1612198.5000 - val_loss: 180552.9531\n",
      "Epoch 812/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1486299.5000 - val_loss: 229954.5156\n",
      "Epoch 813/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2345594.7500 - val_loss: 705467.9375\n",
      "Epoch 814/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1181698.1250 - val_loss: 729069.5625\n",
      "Epoch 815/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 990611.5000 - val_loss: 595085.0000\n",
      "Epoch 816/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1095255.2500 - val_loss: 318646.1562\n",
      "Epoch 817/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1224640.6250 - val_loss: 357132.3125\n",
      "Epoch 818/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1071094.1250 - val_loss: 252466.1406\n",
      "Epoch 819/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3706473.5000 - val_loss: 630090.7500\n",
      "Epoch 820/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1215260.3750 - val_loss: 543761.4375\n",
      "Epoch 821/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1127105.5000 - val_loss: 189644.5625\n",
      "Epoch 822/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 528684.5625 - val_loss: 275878.2188\n",
      "Epoch 823/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 829729.8750 - val_loss: 848610.5000\n",
      "Epoch 824/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1924737.3750 - val_loss: 142523.2031\n",
      "Epoch 825/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 931839.8750 - val_loss: 195061.0000\n",
      "Epoch 826/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1065666.1250 - val_loss: 274754.6250\n",
      "Epoch 827/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 939292.1250 - val_loss: 165908.8906\n",
      "Epoch 828/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 587825.3125 - val_loss: 184243.7969\n",
      "Epoch 829/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 742118.1250 - val_loss: 300231.4375\n",
      "Epoch 830/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 949892.5625 - val_loss: 171234.0625\n",
      "Epoch 831/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1055156.6250 - val_loss: 185826.2344\n",
      "Epoch 832/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 835922.1250 - val_loss: 151128.1719\n",
      "Epoch 833/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2671991.2500 - val_loss: 387399.4688\n",
      "Epoch 834/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1099965.1250 - val_loss: 244692.8125\n",
      "Epoch 835/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1184392.7500 - val_loss: 189625.8750\n",
      "Epoch 836/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1738805.8750 - val_loss: 159580.8594\n",
      "Epoch 837/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2343416.2500 - val_loss: 119298.5703\n",
      "Epoch 838/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1013103.5625 - val_loss: 574480.2500\n",
      "Epoch 839/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1411425.6250 - val_loss: 565837.9375\n",
      "Epoch 840/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 939590.3750 - val_loss: 133665.8594\n",
      "Epoch 841/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 604084.0625 - val_loss: 130628.7188\n",
      "Epoch 842/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 692269.6250 - val_loss: 253914.5312\n",
      "Epoch 843/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 889423.9375 - val_loss: 129367.8359\n",
      "Epoch 844/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 554035.3125 - val_loss: 208665.0781\n",
      "Epoch 845/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 715088.6875 - val_loss: 130895.5391\n",
      "Epoch 846/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 491583.8438 - val_loss: 135349.2969\n",
      "Epoch 847/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 905334.0000 - val_loss: 683840.3750\n",
      "Epoch 848/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1005855.1250 - val_loss: 125588.6797\n",
      "Epoch 849/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 796789.3750 - val_loss: 614297.2500\n",
      "Epoch 850/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1006847.7500 - val_loss: 130551.6641\n",
      "Epoch 851/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 814167.4375 - val_loss: 126643.3047\n",
      "Epoch 852/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 714193.8750 - val_loss: 112748.6406\n",
      "Epoch 853/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 618931.3125 - val_loss: 90239.5469\n",
      "Epoch 854/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1046125.9375 - val_loss: 85830.3750\n",
      "Epoch 855/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 450463.0000 - val_loss: 197556.9531\n",
      "Epoch 856/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 352048.2812 - val_loss: 402475.9375\n",
      "Epoch 857/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 926862.9375 - val_loss: 528826.0625\n",
      "Epoch 858/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8363914.5000 - val_loss: 233807.7188\n",
      "Epoch 859/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 512451.4062 - val_loss: 91362.4219\n",
      "Epoch 860/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 869478.8125 - val_loss: 476666.0625\n",
      "Epoch 861/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 574340.9375 - val_loss: 299680.2500\n",
      "Epoch 862/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 667580.0000 - val_loss: 76243.1016\n",
      "Epoch 863/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 634251.3125 - val_loss: 110467.4375\n",
      "Epoch 864/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 592551.3750 - val_loss: 95482.0391\n",
      "Epoch 865/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 378671.9375 - val_loss: 77739.1719\n",
      "Epoch 866/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 632233.0000 - val_loss: 109501.2969\n",
      "Epoch 867/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 905858.4375 - val_loss: 83480.1719\n",
      "Epoch 868/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3011248.2500 - val_loss: 7309283.5000\n",
      "Epoch 869/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3519540.7500 - val_loss: 1572261.1250\n",
      "Epoch 870/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1040230.9375 - val_loss: 137841.1719\n",
      "Epoch 871/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 954072.3125 - val_loss: 84384.5859\n",
      "Epoch 872/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 335755.0312 - val_loss: 81661.2188\n",
      "Epoch 873/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 548160.6250 - val_loss: 470215.6562\n",
      "Epoch 874/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 565705.1250 - val_loss: 89014.7578\n",
      "Epoch 875/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 404524.3438 - val_loss: 293342.4688\n",
      "Epoch 876/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1010308.1250 - val_loss: 2000605.5000\n",
      "Epoch 877/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1520734.7500 - val_loss: 706962.3750\n",
      "Epoch 878/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 717764.1250 - val_loss: 154398.7812\n",
      "Epoch 879/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 380508.1250 - val_loss: 52093.7266\n",
      "Epoch 880/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 475391.4375 - val_loss: 102561.1484\n",
      "Epoch 881/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 479060.3438 - val_loss: 232727.6250\n",
      "Epoch 882/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 596507.7500 - val_loss: 117290.9609\n",
      "Epoch 883/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 691244.0000 - val_loss: 418570.1562\n",
      "Epoch 884/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 635898.6875 - val_loss: 78546.3750\n",
      "Epoch 885/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 397330.2188 - val_loss: 55581.8047\n",
      "Epoch 886/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 311208.6250 - val_loss: 81733.2891\n",
      "Epoch 887/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 278395.9375 - val_loss: 77045.1719\n",
      "Epoch 888/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 577137.3125 - val_loss: 84405.8516\n",
      "Epoch 889/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 424952.3125 - val_loss: 200970.5469\n",
      "Epoch 890/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 517981.0625 - val_loss: 259572.5000\n",
      "Epoch 891/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 310007.0000 - val_loss: 238012.1094\n",
      "Epoch 892/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 647860.6875 - val_loss: 123318.0312\n",
      "Epoch 893/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 281802.7500 - val_loss: 712655.7500\n",
      "Epoch 894/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 590993.4375 - val_loss: 422716.9688\n",
      "Epoch 895/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 643487.9375 - val_loss: 156428.5781\n",
      "Epoch 896/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 301588.4375 - val_loss: 52819.1172\n",
      "Epoch 897/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 377653.4375 - val_loss: 196475.7031\n",
      "Epoch 898/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 637941.6250 - val_loss: 95336.9297\n",
      "Epoch 899/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 260194.3125 - val_loss: 111991.1250\n",
      "Epoch 900/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 272917.7500 - val_loss: 1190356.2500\n",
      "Epoch 901/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2051485.2500 - val_loss: 439876.6250\n",
      "Epoch 902/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 819838.8750 - val_loss: 73451.3750\n",
      "Epoch 903/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 589219.5625 - val_loss: 86188.3906\n",
      "Epoch 904/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 383506.1562 - val_loss: 201115.4375\n",
      "Epoch 905/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 632852.0625 - val_loss: 41978.6680\n",
      "Epoch 906/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 405330.3750 - val_loss: 111764.2188\n",
      "Epoch 907/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 240870.9375 - val_loss: 106935.9844\n",
      "Epoch 908/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 265419.2188 - val_loss: 447364.2812\n",
      "Epoch 909/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 255654.0156 - val_loss: 284787.7500\n",
      "Epoch 910/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 667904.5000 - val_loss: 35507.6094\n",
      "Epoch 911/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 248110.3750 - val_loss: 62425.2578\n",
      "Epoch 912/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 214173.4062 - val_loss: 37728.1719\n",
      "Epoch 913/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 431335.3438 - val_loss: 376714.5938\n",
      "Epoch 914/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 327625.8438 - val_loss: 38701.1055\n",
      "Epoch 915/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 317869.6875 - val_loss: 94545.4375\n",
      "Epoch 916/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 442700.0625 - val_loss: 102349.0781\n",
      "Epoch 917/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 397294.9688 - val_loss: 687799.0625\n",
      "Epoch 918/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1390423.3750 - val_loss: 1720080.2500\n",
      "Epoch 919/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3209323.0000 - val_loss: 113322.3594\n",
      "Epoch 920/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 289450.0312 - val_loss: 176700.4375\n",
      "Epoch 921/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 814988.3125 - val_loss: 115807.8438\n",
      "Epoch 922/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 317085.2812 - val_loss: 62865.2305\n",
      "Epoch 923/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 250442.7344 - val_loss: 45566.1172\n",
      "Epoch 924/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 701168.8750 - val_loss: 297789.8125\n",
      "Epoch 925/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 387960.5312 - val_loss: 49023.1250\n",
      "Epoch 926/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 554089.0625 - val_loss: 65422.6094\n",
      "Epoch 927/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 235641.5781 - val_loss: 94748.1406\n",
      "Epoch 928/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1376178.0000 - val_loss: 103919.2891\n",
      "Epoch 929/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 411166.4375 - val_loss: 347785.6875\n",
      "Epoch 930/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 282418.9062 - val_loss: 26386.8398\n",
      "Epoch 931/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 346724.9688 - val_loss: 369960.6875\n",
      "Epoch 932/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 717872.6875 - val_loss: 129002.7109\n",
      "Epoch 933/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 159799.3438 - val_loss: 63712.4648\n",
      "Epoch 934/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 234379.3906 - val_loss: 21146.1855\n",
      "Epoch 935/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 274800.1250 - val_loss: 109209.1172\n",
      "Epoch 936/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 293003.8438 - val_loss: 78653.6406\n",
      "Epoch 937/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 255512.7656 - val_loss: 23243.3027\n",
      "Epoch 938/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 101257.0469 - val_loss: 43626.6523\n",
      "Epoch 939/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 168977.2188 - val_loss: 16531.0078\n",
      "Epoch 940/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139518.6719 - val_loss: 393352.9375\n",
      "Epoch 941/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8515629.0000 - val_loss: 2039988.5000\n",
      "Epoch 942/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3780204.0000 - val_loss: 2738292.0000\n",
      "Epoch 943/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3410993.5000 - val_loss: 527435.3125\n",
      "Epoch 944/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1741428.5000 - val_loss: 123467.6562\n",
      "Epoch 945/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1163782.5000 - val_loss: 821471.2500\n",
      "Epoch 946/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1798352.5000 - val_loss: 227597.0469\n",
      "Epoch 947/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 357116.7188 - val_loss: 315181.6562\n",
      "Epoch 948/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2687005.2500 - val_loss: 75273.4531\n",
      "Epoch 949/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 358231.8438 - val_loss: 51506.0625\n",
      "Epoch 950/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 426016.6562 - val_loss: 89237.0312\n",
      "Epoch 951/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 241159.5938 - val_loss: 42372.1641\n",
      "Epoch 952/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 242531.3750 - val_loss: 51009.7578\n",
      "Epoch 953/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 444551.6250 - val_loss: 364374.1562\n",
      "Epoch 954/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 411990.2812 - val_loss: 59531.6523\n",
      "Epoch 955/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 299668.1562 - val_loss: 51649.2305\n",
      "Epoch 956/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 983760.5000 - val_loss: 148027.2344\n",
      "Epoch 957/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 282960.5000 - val_loss: 239587.0781\n",
      "Epoch 958/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 355248.8438 - val_loss: 79090.8516\n",
      "Epoch 959/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 316949.2812 - val_loss: 104352.2500\n",
      "Epoch 960/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 537629.3750 - val_loss: 596201.8750\n",
      "Epoch 961/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 509108.2500 - val_loss: 198658.2188\n",
      "Epoch 962/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 374997.8438 - val_loss: 109434.0938\n",
      "Epoch 963/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 305699.0625 - val_loss: 63246.1719\n",
      "Epoch 964/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 199933.4219 - val_loss: 45198.6719\n",
      "Epoch 965/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 238944.9688 - val_loss: 69172.3906\n",
      "Epoch 966/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 215885.2812 - val_loss: 56733.1836\n",
      "Epoch 967/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 160484.0938 - val_loss: 34089.3242\n",
      "Epoch 968/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 103461.9609 - val_loss: 33444.5000\n",
      "Epoch 969/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147993.7656 - val_loss: 43733.5195\n",
      "Epoch 970/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 533076.6250 - val_loss: 31865.7051\n",
      "Epoch 971/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 187796.5156 - val_loss: 91780.3438\n",
      "Epoch 972/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 134005.6406 - val_loss: 126937.1250\n",
      "Epoch 973/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 188242.8750 - val_loss: 42303.6992\n",
      "Epoch 974/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 581781.3125 - val_loss: 1213662.8750\n",
      "Epoch 975/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1670599.1250 - val_loss: 1979208.8750\n",
      "Epoch 976/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1993139.3750 - val_loss: 237584.8125\n",
      "Epoch 977/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 845918.8125 - val_loss: 75838.4922\n",
      "Epoch 978/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 551445.9375 - val_loss: 137057.9375\n",
      "Epoch 979/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 423056.5625 - val_loss: 74921.8438\n",
      "Epoch 980/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 236357.6875 - val_loss: 109840.9219\n",
      "Epoch 981/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 232856.6094 - val_loss: 133441.9844\n",
      "Epoch 982/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 395258.2188 - val_loss: 28639.0859\n",
      "Epoch 983/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 266301.5312 - val_loss: 42653.5742\n",
      "Epoch 984/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121508.5234 - val_loss: 77969.7422\n",
      "Epoch 985/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 88567.3203 - val_loss: 76203.5156\n",
      "Epoch 986/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 269915.5938 - val_loss: 32815.2031\n",
      "Epoch 987/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 121651.1562 - val_loss: 22149.4336\n",
      "Epoch 988/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 108462.7734 - val_loss: 71664.3516\n",
      "Epoch 989/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 97344.8203 - val_loss: 44118.4570\n",
      "Epoch 990/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 112410.3281 - val_loss: 38049.8672\n",
      "Epoch 991/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 168578.3438 - val_loss: 37478.5156\n",
      "Epoch 992/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 432923.7188 - val_loss: 155359.4375\n",
      "Epoch 993/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 144187.2344 - val_loss: 117868.4141\n",
      "Epoch 994/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 266821.5938 - val_loss: 231326.0625\n",
      "Epoch 995/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 171301.5469 - val_loss: 14158.9648\n",
      "Epoch 996/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 138501.4062 - val_loss: 39168.6172\n",
      "Epoch 997/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 216378.5781 - val_loss: 29160.6602\n",
      "Epoch 998/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 107683.4297 - val_loss: 10904.3340\n",
      "Epoch 999/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137769.0156 - val_loss: 39205.3398\n",
      "Epoch 1000/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60149.0781 - val_loss: 13872.3633\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "[173.19 173.03 174.55 174.15 171.52]\n",
      "[[127.59749]\n",
      " [131.14436]\n",
      " [131.18343]\n",
      " [106.32405]\n",
      " [140.40999]]\n"
     ]
    }
   ],
   "source": [
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=128, activation='relu', input_shape=(X_flat.shape[1],)))  # Input shape is (sequence_length * number_of_features,)\n",
    "model.add(Dropout(0.2))  # Dropout for regularization\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "\n",
    "model.add(Dense(1))  # Output layer for a single prediction\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "history = model.fit(X_flat, Y, epochs=1000, batch_size=32, validation_split=0.2)\n",
    "\n",
    "predictions = model.predict(X_flat)\n",
    "\n",
    "print(targets[:5])\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.7629116531530507\n",
      "Predictions: [173.20205139 172.99509949 173.702052   175.07864731 172.23541946]\n",
      "Actual values: [173.19 173.03 174.55 174.15 171.52]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "num_samples, sequence_length, num_features = X.shape\n",
    "X_train_flattened = X.reshape(num_samples, sequence_length * num_features)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_flattened, Y)\n",
    "\n",
    "y_pred = model.predict(X_train_flattened)\n",
    "\n",
    "mse = mean_squared_error(Y, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "# Print the first few predictions and actual values\n",
    "print(\"Predictions:\", y_pred[:5])\n",
    "print(\"Actual values:\", Y[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pravachanpatra/Documents/PYTHON/AI_ML_DL/Stock_Price_Predictor/venv/lib/python3.12/site-packages/pandas/io/parquet.py:190: UserWarning: The DataFrame has column names of mixed type. They will be converted to strings and not roundtrip correctly.\n",
      "  table = self.api.Table.from_pandas(df, **from_pandas_kwargs)\n"
     ]
    }
   ],
   "source": [
    "# cannot combine because 3d:\n",
    "# tabular_data = pd.DataFrame(features)\n",
    "# tabular_data[\"target_close_price_next_day\"] = pd.DataFrame(targets)\n",
    "# tabular_data\n",
    "# # each column is a dayx-featurey\n",
    "\n",
    "# dont save because its 3d: save features/targets tabular data\n",
    "# tabular_data.to_parquet(\"../data/transformed/tabular_prices_2022-08-02-2024-08-02.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.9815958805094114\n",
      "221\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 0.7365136091476493\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
