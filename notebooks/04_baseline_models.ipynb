{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pravachanpatra/Documents/PYTHON/AI_ML_DL/Stock_Price_Predictor/venv/bin/python\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>target_close_price_next_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56696984.0</td>\n",
       "      <td>164.743195</td>\n",
       "      <td>163.210007</td>\n",
       "      <td>165.350006</td>\n",
       "      <td>165.850006</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>491310.00000</td>\n",
       "      <td>1.659398e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56941340.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363333</td>\n",
       "      <td>63496620.0</td>\n",
       "      <td>-0.073343</td>\n",
       "      <td>171.024002</td>\n",
       "      <td>169.102997</td>\n",
       "      <td>170.947968</td>\n",
       "      <td>167.599106</td>\n",
       "      <td>2.005173</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>173.190002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56696984.0</td>\n",
       "      <td>164.743195</td>\n",
       "      <td>163.210007</td>\n",
       "      <td>165.350006</td>\n",
       "      <td>165.850006</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>491310.00000</td>\n",
       "      <td>1.659485e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56941340.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363333</td>\n",
       "      <td>60280852.0</td>\n",
       "      <td>-0.079148</td>\n",
       "      <td>171.813995</td>\n",
       "      <td>169.102997</td>\n",
       "      <td>171.695312</td>\n",
       "      <td>168.131577</td>\n",
       "      <td>1.902056</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>173.029999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56696984.0</td>\n",
       "      <td>164.743195</td>\n",
       "      <td>163.210007</td>\n",
       "      <td>165.350006</td>\n",
       "      <td>165.850006</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>491310.00000</td>\n",
       "      <td>1.659571e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56941340.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.160000</td>\n",
       "      <td>60127840.0</td>\n",
       "      <td>0.042250</td>\n",
       "      <td>172.722000</td>\n",
       "      <td>169.102997</td>\n",
       "      <td>172.140213</td>\n",
       "      <td>168.598099</td>\n",
       "      <td>0.441202</td>\n",
       "      <td>-0.000924</td>\n",
       "      <td>174.550003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56696984.0</td>\n",
       "      <td>164.743195</td>\n",
       "      <td>163.210007</td>\n",
       "      <td>165.350006</td>\n",
       "      <td>165.850006</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>491310.00000</td>\n",
       "      <td>1.659672e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56941340.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>62428372.0</td>\n",
       "      <td>0.410894</td>\n",
       "      <td>173.212006</td>\n",
       "      <td>169.102997</td>\n",
       "      <td>172.943466</td>\n",
       "      <td>169.164948</td>\n",
       "      <td>0.795744</td>\n",
       "      <td>0.008785</td>\n",
       "      <td>174.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57918768.0</td>\n",
       "      <td>165.126770</td>\n",
       "      <td>164.263336</td>\n",
       "      <td>165.190002</td>\n",
       "      <td>166.503326</td>\n",
       "      <td>163.399994</td>\n",
       "      <td>507545.65625</td>\n",
       "      <td>1.659744e+18</td>\n",
       "      <td>-0.160000</td>\n",
       "      <td>56941340.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>62208356.0</td>\n",
       "      <td>-0.216891</td>\n",
       "      <td>173.549332</td>\n",
       "      <td>169.102997</td>\n",
       "      <td>173.345642</td>\n",
       "      <td>169.639709</td>\n",
       "      <td>0.755515</td>\n",
       "      <td>-0.002292</td>\n",
       "      <td>171.520004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>38468544.0</td>\n",
       "      <td>234.299194</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>234.820007</td>\n",
       "      <td>236.270004</td>\n",
       "      <td>232.330002</td>\n",
       "      <td>623906.00000</td>\n",
       "      <td>1.721102e+18</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>52547780.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>44989644.0</td>\n",
       "      <td>-0.040710</td>\n",
       "      <td>218.037994</td>\n",
       "      <td>225.936493</td>\n",
       "      <td>218.969620</td>\n",
       "      <td>222.390121</td>\n",
       "      <td>0.377636</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>218.240005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>55878904.0</td>\n",
       "      <td>228.839600</td>\n",
       "      <td>229.449997</td>\n",
       "      <td>228.880005</td>\n",
       "      <td>231.459900</td>\n",
       "      <td>226.639999</td>\n",
       "      <td>811024.00000</td>\n",
       "      <td>1.721189e+18</td>\n",
       "      <td>-5.940000</td>\n",
       "      <td>53399272.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>40082904.0</td>\n",
       "      <td>-0.042438</td>\n",
       "      <td>217.977997</td>\n",
       "      <td>225.414505</td>\n",
       "      <td>218.726410</td>\n",
       "      <td>221.994873</td>\n",
       "      <td>0.292077</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>218.800003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>64346032.0</td>\n",
       "      <td>225.181000</td>\n",
       "      <td>230.279999</td>\n",
       "      <td>224.179993</td>\n",
       "      <td>230.440002</td>\n",
       "      <td>222.270004</td>\n",
       "      <td>844538.00000</td>\n",
       "      <td>1.721275e+18</td>\n",
       "      <td>-4.700000</td>\n",
       "      <td>55351372.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>38128876.0</td>\n",
       "      <td>0.157249</td>\n",
       "      <td>218.240005</td>\n",
       "      <td>224.705505</td>\n",
       "      <td>218.750946</td>\n",
       "      <td>221.690598</td>\n",
       "      <td>0.329983</td>\n",
       "      <td>0.002566</td>\n",
       "      <td>222.080002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>48020040.0</td>\n",
       "      <td>224.735596</td>\n",
       "      <td>224.820007</td>\n",
       "      <td>224.309998</td>\n",
       "      <td>226.800003</td>\n",
       "      <td>223.274994</td>\n",
       "      <td>612739.00000</td>\n",
       "      <td>1.721362e+18</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>53445452.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>39847940.0</td>\n",
       "      <td>0.190291</td>\n",
       "      <td>219.063995</td>\n",
       "      <td>224.431000</td>\n",
       "      <td>219.860626</td>\n",
       "      <td>221.727676</td>\n",
       "      <td>1.710839</td>\n",
       "      <td>0.014991</td>\n",
       "      <td>218.360001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>46999404.0</td>\n",
       "      <td>224.829895</td>\n",
       "      <td>225.550003</td>\n",
       "      <td>224.193329</td>\n",
       "      <td>227.126663</td>\n",
       "      <td>223.213333</td>\n",
       "      <td>643436.00000</td>\n",
       "      <td>1.721434e+18</td>\n",
       "      <td>-0.116667</td>\n",
       "      <td>50742584.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.720000</td>\n",
       "      <td>44419056.0</td>\n",
       "      <td>0.262319</td>\n",
       "      <td>219.125336</td>\n",
       "      <td>223.822006</td>\n",
       "      <td>219.360413</td>\n",
       "      <td>221.406952</td>\n",
       "      <td>1.670571</td>\n",
       "      <td>-0.016751</td>\n",
       "      <td>218.360001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>719 rows × 222 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1           2           3           4           5  \\\n",
       "0    56696984.0  164.743195  163.210007  165.350006  165.850006  163.000000   \n",
       "1    56696984.0  164.743195  163.210007  165.350006  165.850006  163.000000   \n",
       "2    56696984.0  164.743195  163.210007  165.350006  165.850006  163.000000   \n",
       "3    56696984.0  164.743195  163.210007  165.350006  165.850006  163.000000   \n",
       "4    57918768.0  165.126770  164.263336  165.190002  166.503326  163.399994   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "714  38468544.0  234.299194  235.000000  234.820007  236.270004  232.330002   \n",
       "715  55878904.0  228.839600  229.449997  228.880005  231.459900  226.639999   \n",
       "716  64346032.0  225.181000  230.279999  224.179993  230.440002  222.270004   \n",
       "717  48020040.0  224.735596  224.820007  224.309998  226.800003  223.274994   \n",
       "718  46999404.0  224.829895  225.550003  224.193329  227.126663  223.213333   \n",
       "\n",
       "                6             7         8           9  ...       212  \\\n",
       "0    491310.00000  1.659398e+18  0.000000  56941340.0  ...  0.363333   \n",
       "1    491310.00000  1.659485e+18  0.000000  56941340.0  ...  0.363333   \n",
       "2    491310.00000  1.659571e+18  0.000000  56941340.0  ... -0.160000   \n",
       "3    491310.00000  1.659672e+18  0.000000  56941340.0  ...  1.520000   \n",
       "4    507545.65625  1.659744e+18 -0.160000  56941340.0  ... -0.400000   \n",
       "..            ...           ...       ...         ...  ...       ...   \n",
       "714  623906.00000  1.721102e+18  0.420000  52547780.0  ...  0.093333   \n",
       "715  811024.00000  1.721189e+18 -5.940000  53399272.0  ...  0.093333   \n",
       "716  844538.00000  1.721275e+18 -4.700000  55351372.0  ...  0.560000   \n",
       "717  612739.00000  1.721362e+18  0.130000  53445452.0  ...  3.280000   \n",
       "718  643436.00000  1.721434e+18 -0.116667  50742584.0  ... -3.720000   \n",
       "\n",
       "            213       214         215         216         217         218  \\\n",
       "0    63496620.0 -0.073343  171.024002  169.102997  170.947968  167.599106   \n",
       "1    60280852.0 -0.079148  171.813995  169.102997  171.695312  168.131577   \n",
       "2    60127840.0  0.042250  172.722000  169.102997  172.140213  168.598099   \n",
       "3    62428372.0  0.410894  173.212006  169.102997  172.943466  169.164948   \n",
       "4    62208356.0 -0.216891  173.549332  169.102997  173.345642  169.639709   \n",
       "..          ...       ...         ...         ...         ...         ...   \n",
       "714  44989644.0 -0.040710  218.037994  225.936493  218.969620  222.390121   \n",
       "715  40082904.0 -0.042438  217.977997  225.414505  218.726410  221.994873   \n",
       "716  38128876.0  0.157249  218.240005  224.705505  218.750946  221.690598   \n",
       "717  39847940.0  0.190291  219.063995  224.431000  219.860626  221.727676   \n",
       "718  44419056.0  0.262319  219.125336  223.822006  219.360413  221.406952   \n",
       "\n",
       "          219       220  target_close_price_next_day  \n",
       "0    2.005173  0.002107                   173.190002  \n",
       "1    1.902056  0.002102                   173.029999  \n",
       "2    0.441202 -0.000924                   174.550003  \n",
       "3    0.795744  0.008785                   174.149994  \n",
       "4    0.755515 -0.002292                   171.520004  \n",
       "..        ...       ...                          ...  \n",
       "714  0.377636  0.000428                   218.240005  \n",
       "715  0.292077  0.000428                   218.800003  \n",
       "716  0.329983  0.002566                   222.080002  \n",
       "717  1.710839  0.014991                   218.360001  \n",
       "718  1.670571 -0.016751                   218.360001  \n",
       "\n",
       "[719 rows x 222 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "# Verify kernal path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "tabular_prices = pd.read_parquet(\"../data/transformed/tabular_prices_2022-08-02-2024-08-02.parquet\")\n",
    "tabular_prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (575, 221)\n",
      "y_train: (575,)\n",
      "X_test: (144, 221)\n",
      "y_test: (144,)\n"
     ]
    }
   ],
   "source": [
    "# TRAIN TEST SPLIT\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_test_split_tabular(tabular_prices, target_column_name=\"target_close_price_next_day\", test_size=0.2, random_state=42):\n",
    "    # seperate features/targets\n",
    "    X = tabular_prices.drop(columns=[target_column_name])\n",
    "    y = tabular_prices[target_column_name]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split_tabular(tabular_prices)\n",
    "print(f\"X_train: {X_train.shape}\") # (examples-in-train, num-features)\n",
    "print(f\"y_train: {y_train.shape}\") # (examples-in-train,) 1D beceause only one target\n",
    "print(f\"X_test: {X_test.shape}\")   # (examples-in-test, num-features)\n",
    "print(f\"y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 6.529209730146054\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'Mean Squared Error: {mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 5.54467381890986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and calculate MSE\n",
    "y_pred = rf_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Random Forest MSE: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120    145.470001\n",
       "164    143.960007\n",
       "39     150.429993\n",
       "551    182.122498\n",
       "199    145.910004\n",
       "550    182.309998\n",
       "65     143.860001\n",
       "513    186.190002\n",
       "78     150.649994\n",
       "596    168.839996\n",
       "Name: target_close_price_next_day, dtype: float32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([143.59186752, 142.31713364, 152.68413315, 182.66161652,\n",
       "       145.84414139, 184.22800034, 142.59016678, 185.21798325,\n",
       "       153.19100693, 170.26291656])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.9796495360135436e+35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pravachanpatra/Documents/PYTHON/AI_ML_DL/Stock_Price_Predictor/venv/lib/python3.12/site-packages/sklearn/neural_network/_stochastic_optimizers.py:275: RuntimeWarning: overflow encountered in square\n",
      "  self.beta_2 * v + (1 - self.beta_2) * (grad**2)\n",
      "/Users/pravachanpatra/Documents/PYTHON/AI_ML_DL/Stock_Price_Predictor/venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "nn_model = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', max_iter=500, random_state=42)\n",
    "\n",
    "nn_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nn_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.842042706812208e-06\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = xgb_model.predict(X_train)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 42363\n",
      "[LightGBM] [Info] Number of data points in the train set: 575, number of used features: 221\n",
      "[LightGBM] [Info] Start training from score 174.023416\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Mean Squared Error: 5.903373428048752\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(objective='regression', n_estimators=100, learning_rate=0.1, max_depth=-1, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = lgb_model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
