{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pravachanpatra/Documents/PYTHON/AI_ML_DL/Stock_Price_Predictor/venv/bin/python\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>vw_avr_price</th>\n",
       "      <th>open_price</th>\n",
       "      <th>close_price</th>\n",
       "      <th>high_price</th>\n",
       "      <th>low_price</th>\n",
       "      <th>num_transactions</th>\n",
       "      <th>datetime</th>\n",
       "      <th>price_diff</th>\n",
       "      <th>volume_sma_5</th>\n",
       "      <th>volume_change</th>\n",
       "      <th>SMA_5</th>\n",
       "      <th>SMA_20</th>\n",
       "      <th>EMA_5</th>\n",
       "      <th>EMA_20</th>\n",
       "      <th>vol_5</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.669698e+07</td>\n",
       "      <td>164.743200</td>\n",
       "      <td>163.210000</td>\n",
       "      <td>165.35</td>\n",
       "      <td>165.850000</td>\n",
       "      <td>163.00</td>\n",
       "      <td>491310.000000</td>\n",
       "      <td>2022-08-02 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.694134e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>165.318000</td>\n",
       "      <td>169.103000</td>\n",
       "      <td>165.350000</td>\n",
       "      <td>165.350000</td>\n",
       "      <td>0.071554</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.669698e+07</td>\n",
       "      <td>164.743200</td>\n",
       "      <td>163.210000</td>\n",
       "      <td>165.35</td>\n",
       "      <td>165.850000</td>\n",
       "      <td>163.00</td>\n",
       "      <td>491310.000000</td>\n",
       "      <td>2022-08-03 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.694134e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>165.318000</td>\n",
       "      <td>169.103000</td>\n",
       "      <td>165.350000</td>\n",
       "      <td>165.350000</td>\n",
       "      <td>0.071554</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.669698e+07</td>\n",
       "      <td>164.743200</td>\n",
       "      <td>163.210000</td>\n",
       "      <td>165.35</td>\n",
       "      <td>165.850000</td>\n",
       "      <td>163.00</td>\n",
       "      <td>491310.000000</td>\n",
       "      <td>2022-08-04 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.694134e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>165.318000</td>\n",
       "      <td>169.103000</td>\n",
       "      <td>165.350000</td>\n",
       "      <td>165.350000</td>\n",
       "      <td>0.071554</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.669698e+07</td>\n",
       "      <td>164.743200</td>\n",
       "      <td>163.210000</td>\n",
       "      <td>165.35</td>\n",
       "      <td>165.850000</td>\n",
       "      <td>163.00</td>\n",
       "      <td>491310.000000</td>\n",
       "      <td>2022-08-05 04:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.694134e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>165.318000</td>\n",
       "      <td>169.103000</td>\n",
       "      <td>165.350000</td>\n",
       "      <td>165.350000</td>\n",
       "      <td>0.071554</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.791877e+07</td>\n",
       "      <td>165.126767</td>\n",
       "      <td>164.263333</td>\n",
       "      <td>165.19</td>\n",
       "      <td>166.503333</td>\n",
       "      <td>163.40</td>\n",
       "      <td>507545.666667</td>\n",
       "      <td>2022-08-06 00:00:00</td>\n",
       "      <td>-0.160000</td>\n",
       "      <td>5.694134e+07</td>\n",
       "      <td>0.021549</td>\n",
       "      <td>165.318000</td>\n",
       "      <td>169.103000</td>\n",
       "      <td>165.296667</td>\n",
       "      <td>165.334762</td>\n",
       "      <td>0.071554</td>\n",
       "      <td>-0.000968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>3.515373e+07</td>\n",
       "      <td>218.131900</td>\n",
       "      <td>216.960000</td>\n",
       "      <td>218.24</td>\n",
       "      <td>219.300000</td>\n",
       "      <td>215.75</td>\n",
       "      <td>604680.000000</td>\n",
       "      <td>2024-07-29 04:00:00</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>4.008290e+07</td>\n",
       "      <td>-0.042438</td>\n",
       "      <td>217.978000</td>\n",
       "      <td>225.414500</td>\n",
       "      <td>218.726415</td>\n",
       "      <td>221.994869</td>\n",
       "      <td>0.292077</td>\n",
       "      <td>0.000428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>4.068162e+07</td>\n",
       "      <td>218.405900</td>\n",
       "      <td>219.190000</td>\n",
       "      <td>218.80</td>\n",
       "      <td>220.325000</td>\n",
       "      <td>216.12</td>\n",
       "      <td>584305.000000</td>\n",
       "      <td>2024-07-30 04:00:00</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>3.812887e+07</td>\n",
       "      <td>0.157249</td>\n",
       "      <td>218.240000</td>\n",
       "      <td>224.705500</td>\n",
       "      <td>218.750943</td>\n",
       "      <td>221.690596</td>\n",
       "      <td>0.329983</td>\n",
       "      <td>0.002566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>4.842297e+07</td>\n",
       "      <td>222.344100</td>\n",
       "      <td>221.440000</td>\n",
       "      <td>222.08</td>\n",
       "      <td>223.820000</td>\n",
       "      <td>220.63</td>\n",
       "      <td>668833.000000</td>\n",
       "      <td>2024-07-31 04:00:00</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>3.984794e+07</td>\n",
       "      <td>0.190291</td>\n",
       "      <td>219.064000</td>\n",
       "      <td>224.431000</td>\n",
       "      <td>219.860629</td>\n",
       "      <td>221.727682</td>\n",
       "      <td>1.710839</td>\n",
       "      <td>0.014991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>6.112524e+07</td>\n",
       "      <td>219.477300</td>\n",
       "      <td>224.370000</td>\n",
       "      <td>218.36</td>\n",
       "      <td>224.480000</td>\n",
       "      <td>217.02</td>\n",
       "      <td>876046.000000</td>\n",
       "      <td>2024-08-01 04:00:00</td>\n",
       "      <td>-3.720000</td>\n",
       "      <td>4.441905e+07</td>\n",
       "      <td>0.262319</td>\n",
       "      <td>219.125333</td>\n",
       "      <td>223.822000</td>\n",
       "      <td>219.360419</td>\n",
       "      <td>221.406950</td>\n",
       "      <td>1.670571</td>\n",
       "      <td>-0.016751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>6.112524e+07</td>\n",
       "      <td>219.477300</td>\n",
       "      <td>224.370000</td>\n",
       "      <td>218.36</td>\n",
       "      <td>224.480000</td>\n",
       "      <td>217.02</td>\n",
       "      <td>876046.000000</td>\n",
       "      <td>2024-08-02 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.930176e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>219.168000</td>\n",
       "      <td>223.148667</td>\n",
       "      <td>219.026946</td>\n",
       "      <td>221.116765</td>\n",
       "      <td>1.641804</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>732 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           volume  vw_avr_price  open_price  close_price  high_price  \\\n",
       "0    5.669698e+07    164.743200  163.210000       165.35  165.850000   \n",
       "1    5.669698e+07    164.743200  163.210000       165.35  165.850000   \n",
       "2    5.669698e+07    164.743200  163.210000       165.35  165.850000   \n",
       "3    5.669698e+07    164.743200  163.210000       165.35  165.850000   \n",
       "4    5.791877e+07    165.126767  164.263333       165.19  166.503333   \n",
       "..            ...           ...         ...          ...         ...   \n",
       "727  3.515373e+07    218.131900  216.960000       218.24  219.300000   \n",
       "728  4.068162e+07    218.405900  219.190000       218.80  220.325000   \n",
       "729  4.842297e+07    222.344100  221.440000       222.08  223.820000   \n",
       "730  6.112524e+07    219.477300  224.370000       218.36  224.480000   \n",
       "731  6.112524e+07    219.477300  224.370000       218.36  224.480000   \n",
       "\n",
       "     low_price  num_transactions            datetime  price_diff  \\\n",
       "0       163.00     491310.000000 2022-08-02 00:00:00    0.000000   \n",
       "1       163.00     491310.000000 2022-08-03 00:00:00    0.000000   \n",
       "2       163.00     491310.000000 2022-08-04 00:00:00    0.000000   \n",
       "3       163.00     491310.000000 2022-08-05 04:00:00    0.000000   \n",
       "4       163.40     507545.666667 2022-08-06 00:00:00   -0.160000   \n",
       "..         ...               ...                 ...         ...   \n",
       "727     215.75     604680.000000 2024-07-29 04:00:00    0.093333   \n",
       "728     216.12     584305.000000 2024-07-30 04:00:00    0.560000   \n",
       "729     220.63     668833.000000 2024-07-31 04:00:00    3.280000   \n",
       "730     217.02     876046.000000 2024-08-01 04:00:00   -3.720000   \n",
       "731     217.02     876046.000000 2024-08-02 00:00:00    0.000000   \n",
       "\n",
       "     volume_sma_5  volume_change       SMA_5      SMA_20       EMA_5  \\\n",
       "0    5.694134e+07       0.000000  165.318000  169.103000  165.350000   \n",
       "1    5.694134e+07       0.000000  165.318000  169.103000  165.350000   \n",
       "2    5.694134e+07       0.000000  165.318000  169.103000  165.350000   \n",
       "3    5.694134e+07       0.000000  165.318000  169.103000  165.350000   \n",
       "4    5.694134e+07       0.021549  165.318000  169.103000  165.296667   \n",
       "..            ...            ...         ...         ...         ...   \n",
       "727  4.008290e+07      -0.042438  217.978000  225.414500  218.726415   \n",
       "728  3.812887e+07       0.157249  218.240000  224.705500  218.750943   \n",
       "729  3.984794e+07       0.190291  219.064000  224.431000  219.860629   \n",
       "730  4.441905e+07       0.262319  219.125333  223.822000  219.360419   \n",
       "731  4.930176e+07       0.000000  219.168000  223.148667  219.026946   \n",
       "\n",
       "         EMA_20     vol_5  daily_return  \n",
       "0    165.350000  0.071554      0.000000  \n",
       "1    165.350000  0.071554      0.000000  \n",
       "2    165.350000  0.071554      0.000000  \n",
       "3    165.350000  0.071554      0.000000  \n",
       "4    165.334762  0.071554     -0.000968  \n",
       "..          ...       ...           ...  \n",
       "727  221.994869  0.292077      0.000428  \n",
       "728  221.690596  0.329983      0.002566  \n",
       "729  221.727682  1.710839      0.014991  \n",
       "730  221.406950  1.670571     -0.016751  \n",
       "731  221.116765  1.641804      0.000000  \n",
       "\n",
       "[732 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os\n",
    "print(sys.executable)\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "# Add the directory to sys.path\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "# Verify kernal path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "ts_prices = pd.read_parquet(\"../data/transformed/validated_prices_2022-08-02-2024-08-02.parquet\")\n",
    "ts_prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TRAIN TEST SPLIT\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# def train_test_split_tabular(tabular_prices, target_column_name=\"target_close_price_next_day\", test_size=0.2, random_state=42):\n",
    "#     # seperate features/targets\n",
    "#     X = tabular_prices.drop(columns=[target_column_name])\n",
    "#     y = tabular_prices[target_column_name]\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "#     return X_train, X_test, y_train, y_test\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split_tabular(tabular_prices)\n",
    "# print(f\"X_train: {X_train.shape}\") # (examples-in-train, num-features)\n",
    "# print(f\"y_train: {y_train.shape}\") # (examples-in-train,) 1D beceause only one target\n",
    "# print(f\"X_test: {X_test.shape}\")   # (examples-in-test, num-features)\n",
    "# print(f\"y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences/examples: 718\n",
      "Last val: 172.82666666666665\n",
      "Target val: 173.19\n"
     ]
    }
   ],
   "source": [
    "from src.data import transform_ts_data_into_features_target\n",
    "\n",
    "\n",
    "n_previous_days = 12  # make sure this constant across all uses\n",
    "step_size = 1\n",
    "features, targets = transform_ts_data_into_features_target(ts_prices, n_previous_days, step_size)\n",
    "\n",
    "\n",
    "X = features\n",
    "Y = targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.7629116531530507\n",
      "Predictions: [173.20205139 172.99509949 173.702052   175.07864731 172.23541946]\n",
      "Actual values: [173.19 173.03 174.55 174.15 171.52]\n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST REGRESSOR\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "num_samples, sequence_length, num_features = X.shape\n",
    "X_train_flattened = X.reshape(num_samples, sequence_length * num_features)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_flattened, Y)\n",
    "\n",
    "y_pred = model.predict(X_train_flattened)\n",
    "\n",
    "mse = mean_squared_error(Y, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "# Print the first few predictions and actual values\n",
    "print(\"Predictions:\", y_pred[:5])\n",
    "print(\"Actual values:\", Y[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 49836\n",
      "[LightGBM] [Info] Number of data points in the train set: 718, number of used features: 208\n",
      "[LightGBM] [Info] Start training from score 173.174972\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "Mean Squared Error: 0.17976092839153793\n",
      "Predictions: [173.23664987 173.0460973  174.2475737  174.32297937 171.63375832]\n",
      "Actual values: [173.19 173.03 174.55 174.15 171.52]\n",
      "\n",
      "Single Prediction: [173.23664987]\n",
      "Actual value: 173.19\n"
     ]
    }
   ],
   "source": [
    "# LIGHTGBM REGRESSOR\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "num_samples, sequence_length, num_features = X.shape\n",
    "X_flattened = X.reshape(num_samples, sequence_length * num_features)\n",
    "\n",
    "# Create the LightGBM Regressor model\n",
    "lgb_model = lgb.LGBMRegressor(objective='regression', n_estimators=100, learning_rate=0.1, max_depth=-1, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "lgb_model.fit(X_flattened, Y)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = lgb_model.predict(X_flattened)\n",
    "\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(Y, y_pred)\n",
    "print(f\"\\nMean Squared Error: {mse}\")\n",
    "\n",
    "# Print the first few predictions and actual values\n",
    "print(\"Predictions:\", y_pred[:5])\n",
    "print(\"Actual values:\", Y[:5])\n",
    "\n",
    "single_example = X[0].reshape(1, -1)  # use indx to get first example with is a sequence of days [[]] and reshape/flatten it to a vector\n",
    "single_prediction = lgb_model.predict(single_example)\n",
    "print(\"\\nSingle Prediction:\", single_prediction)\n",
    "print(\"Actual value:\", Y[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LSTM\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "# from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "\n",
    "# X = features\n",
    "# Y = targets\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Bidirectional(LSTM(units=100, return_sequences=True, input_shape=(X.shape[1], X.shape[2]))))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(units=100))\n",
    "# model.add(Dense(1))  # Output layer for a single prediction\n",
    "\n",
    "# model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# history = model.fit(X, Y, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# predictions = model.predict(X)\n",
    "\n",
    "# # Example: print the first few predictions\n",
    "# print(targets[:5])\n",
    "# print(predictions[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RNN\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(SimpleRNN(units=200, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
    "# model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
    "# model.add(SimpleRNN(units=30))  # Second RNN layer\n",
    "# model.add(Dense(1))  # Output layer for a single prediction\n",
    "\n",
    "# model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# history = model.fit(X, Y, epochs=10, batch_size=32, validation_split=0.2)\n",
    "# predictions = model.predict(X)\n",
    "\n",
    "# # Example: print the first few predictions\n",
    "# print(targets[:5])\n",
    "# print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
